from flask import Blueprint, request, jsonify, send_file
import pandas as pd
import os
import json
import glob
from collections import Counter
from openpyxl import Workbook
from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
from openpyxl.utils import get_column_letter
import datetime
from werkzeug.utils import secure_filename
import re

excel_bp = Blueprint('excel', __name__)

# Configuration
UPLOAD_FOLDER = os.path.abspath('uploads')
PROCESSED_FOLDER = os.path.abspath('processed')
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(PROCESSED_FOLDER, exist_ok=True)

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in {'xlsx', 'xls'}

def find_data_start_row(filepath):
    """üîç Trouve la ligne o√π commencent vraiment les donn√©es"""
    print(f"üîç D√©tection du d√©but des donn√©es dans {filepath}")
    try:
        # Lire les 20 premi√®res lignes sans en-t√™tes
        preview_df = pd.read_excel(filepath, header=None, nrows=20)
        
        for idx, row in preview_df.iterrows():
            # Chercher une ligne qui contient des en-t√™tes typiques
            row_str = ' '.join([str(val) for val in row if pd.notna(val)]).lower()
            
            # Mots-cl√©s indiquant des en-t√™tes de donn√©es
            header_keywords = ['entity', 'date', 'transaction', 'period', 'amount', 'account', 'description', 'bank']
            
            if any(keyword in row_str for keyword in header_keywords):
                print(f"‚úÖ Donn√©es d√©tect√©es √† partir de la ligne {idx + 1}")
                return idx
        
        # Si aucune ligne d'en-t√™te d√©tect√©e, chercher la premi√®re ligne avec plusieurs valeurs non-nulles
        for idx, row in preview_df.iterrows():
            non_null_count = sum(1 for val in row if pd.notna(val) and str(val).strip() != '')
            if non_null_count >= 3:  # Au moins 3 colonnes avec des donn√©es
                print(f"‚úÖ Donn√©es d√©tect√©es √† partir de la ligne {idx + 1} (par nombre de colonnes)")
                return idx
        
        print("‚ö†Ô∏è Impossible de d√©tecter le d√©but des donn√©es, utilisation de la ligne 1")
        return 0
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors de la d√©tection du d√©but des donn√©es: {e}")
        return 0

def read_excel_smart(filepath):
    """üìä Lit le fichier Excel en d√©tectant automatiquement o√π commencent les donn√©es"""
    print(f"üìä Lecture intelligente de {filepath}")
    
    start_row = find_data_start_row(filepath)
    
    # Lire le fichier en sp√©cifiant la ligne de d√©part
    df = pd.read_excel(filepath, header=start_row)
    
    # Nettoyer les noms de colonnes (enlever les espaces, caract√®res bizarres)
    df.columns = [str(col).strip() if pd.notna(col) else f'Unnamed_{i}' for i, col in enumerate(df.columns)]
    
    # Supprimer les lignes compl√®tement vides
    df = df.dropna(how='all')
    
    print(f"üìä Fichier lu avec succ√®s: {df.shape[0]} lignes, {df.shape[1]} colonnes")
    print(f"üìã Colonnes d√©tect√©es: {list(df.columns)}")
    
    return df

def clean_column_names(df):
    """üßπ Standardise les noms de colonnes avec plus de flexibilit√©"""
    print("üßπ Nettoyage des noms de colonnes...")
    
    # üîç DIAGNOSTIC : Avant nettoyage
    print(f"üîç Colonnes AVANT nettoyage: {list(df.columns)}")
    
    column_mapping = {
        # Descriptions
        'description': 'Description', 'descrip': 'Descrip', 'desc': 'Description',
        'libelle': 'Description', 'libell√©': 'Description', 'detail': 'Description',
     
        
        # Autres colonnes
        'nature': 'Nature', 'reference': 'Reference', 'service': 'Service', 
        'vessel': 'Vessel', 'amount': 'Amount CCYs', 'amount_usd': 'Amount USD', 
        'rate': 'Rate FX', 'bank': 'Bank account', 'ccy': 'CCY', 'currency': 'CCY'
    }
    
    rename_dict = {}
    for col in df.columns:
        if pd.isna(col) or col == '':
            continue
        
        col_lower = str(col).lower().strip()
        
        # Correspondance exacte
        if col_lower in column_mapping:
            rename_dict[col] = column_mapping[col_lower]
        else:
            # Correspondance partielle pour Description
            if any(desc_key in col_lower for desc_key in ['description', 'descrip', 'desc', 'libelle', 'detail']):
                if 'Description' not in df.columns:
                    rename_dict[col] = 'Description'
            
            # Autres correspondances partielles
            for old_name, new_name in column_mapping.items():
                if old_name in col_lower and new_name not in df.columns:
                    rename_dict[col] = new_name
                    break
    
    if rename_dict:
        df = df.rename(columns=rename_dict)
        print(f"üîÑ Colonnes renomm√©es: {rename_dict}")
    
    return df

def apply_formatting(df, filepath):
    """Applique un formatage Excel professionnel"""
    
    # üîß Formatter les colonnes num√©riques AVANT d'√©crire dans Excel
    numeric_columns = ['Rate FX', 'Amount CCYs', 'Amount USD', 'Total']
    for col in numeric_columns:
        if col in df.columns:
            try:
                # Convertir en num√©rique, remplacer les erreurs par NaN
                df[col] = pd.to_numeric(df[col], errors='coerce')
                print(f"‚úÖ Colonne '{col}' convertie en num√©rique")
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur conversion num√©rique pour '{col}': {e}")
    
    wb = Workbook()
    ws = wb.active
    
    # Styles
    header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
    header_font = Font(color="FFFFFF", bold=True, size=11)
    data_font = Font(size=10)
    negative_font = Font(size=10, color="FF0000")
    
    # En-t√™tes
    for col_idx, col_name in enumerate(df.columns, 1):
        cell = ws.cell(row=1, column=col_idx, value=str(col_name))
        cell.fill = header_fill
        cell.font = header_font
        cell.alignment = Alignment(horizontal="center", vertical="center")
    
    # Donn√©es avec formatage sp√©cialis√©
    for row_idx, (_, row) in enumerate(df.iterrows(), 2):
        for col_idx, value in enumerate(row, 1):
            cell = ws.cell(row=row_idx, column=col_idx, value=value)
            cell.font = data_font
            
            col_name = df.columns[col_idx - 1]
            
            # üí∞ Format num√©rique pour les colonnes financi√®res
            if col_name in numeric_columns:
                try:
                    if pd.notna(value) and value != '':
                        cell.value = float(value)
                        if col_name in ['Amount CCYs', 'Amount USD', 'Total']:
                            cell.number_format = '#,##0.00'  # Format mon√©taire
                        elif col_name == 'Rate FX':
                            cell.number_format = '0.00000'   # Format taux (5 d√©cimales)
                        
                        # Couleur rouge pour les montants n√©gatifs
                        if float(value) < 0:
                            cell.font = negative_font
                except (ValueError, TypeError):
                    pass
    
    # Ajuster largeurs et ajouter filtres
    for col_idx in range(1, len(df.columns) + 1):
        col_name = df.columns[col_idx - 1]
        if col_name in numeric_columns:
            ws.column_dimensions[get_column_letter(col_idx)].width = 18  # Plus large pour les nombres
        else:
            ws.column_dimensions[get_column_letter(col_idx)].width = 15
    
    ws.auto_filter.ref = f"A1:{get_column_letter(len(df.columns))}{len(df) + 1}"
    
    wb.save(filepath)
    return True

def format_period_column(df):
        """üìÖ Formate la colonne Period au format 'mois-aa'"""
        if 'Period' not in df.columns:
            return df
        
        print("üìÖ Formatage de la colonne Period...")
        
        try:
            # Convertir en datetime si ce n'est pas d√©j√† fait
            df['Period'] = pd.to_datetime(df['Period'], errors='coerce')
            
            # Cr√©er le mapping fran√ßais des mois
            mois_fr = {
                1: 'janv.', 2: 'f√©vr.', 3: 'mars', 4: 'avr.',
                5: 'mai', 6: 'juin', 7: 'juil.', 8: 'ao√ªt',
                9: 'sept.', 10: 'oct.', 11: 'nov.', 12: 'd√©c.'
            }
            
            # Formatter au format fran√ßais
            def format_period(date):
                if pd.isna(date):
                    return ''
                try:
                    mois = mois_fr.get(date.month, str(date.month))
                    annee = str(date.year)[-2:]  # 2 derniers chiffres de l'ann√©e
                    return f"{mois}-{annee}"
                except:
                    return str(date)
            
            df['Period'] = df['Period'].apply(format_period)
            print("‚úÖ Colonne Period format√©e au format fran√ßais")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors du formatage de Period: {e}")
        
        return df

class RulesPredictor:
    """ü§ñ Syst√®me de r√®gles avec logs d√©taill√©s"""
    
    def __init__(self):
        self.rules = []
        self.stats = {'rules_loaded': 0, 'rules_applied': 0, 'cells_filled': 0}
    
    
    def load_rules(self):
        """üìã Charge les r√®gles depuis les fichiers JSON"""
        print("üìã Chargement des r√®gles...")
        
        # Chercher les fichiers de r√®gles dans diff√©rents r√©pertoires
        search_patterns = [
            "rules_*.json", 
            "**/rules_*.json", 
            "model_auto_remplissage/rules_*.json",
            "model_auto_remplissage/**/rules_*.json"
        ]
        
        rule_files = []
        for pattern in search_patterns:
            rule_files.extend(glob.glob(pattern, recursive=True))
        
        if not rule_files:
            print("‚ùå Aucun fichier de r√®gles trouv√©")
            return False
        
        # Prendre le fichier le plus r√©cent
        latest_file = max(rule_files, key=os.path.getctime)
        print(f"üìÇ Fichier de r√®gles s√©lectionn√©: {latest_file}")
        
        try:
            with open(latest_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.rules = data.get('rules', [])
            self.stats['rules_loaded'] = len(self.rules)
            print(f"‚úÖ {len(self.rules)} r√®gles charg√©es avec succ√®s")
            
            # Afficher quelques exemples de r√®gles
            if self.rules:
                print("üìã Exemples de r√®gles charg√©es:")
                for i, rule in enumerate(self.rules[:3]):
                    pattern = rule.get('pattern', '')[:50]
                    cols = list(rule.get('fixed_columns', {}).keys())
                    print(f"   ‚Ä¢ R√®gle {i+1}: '{pattern}...' ‚Üí Remplit {cols}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement des r√®gles: {e}")
            return False
    
    def apply_rules(self, df):
        """‚öôÔ∏è Applique les r√®gles avec logs d√©taill√©s"""
        print("‚öôÔ∏è Application des r√®gles de remplissage...")
        
        if not self.rules:
            print("‚ö†Ô∏è Aucune r√®gle disponible")
            return df
        
        # V√©rifier la pr√©sence de la colonne Description
        if 'Description' not in df.columns:
            print("‚ùå Colonne 'Description' manquante, impossible d'appliquer les r√®gles")
            return df
        
        print(f"üìä Colonne Description d√©tect√©e avec {df['Description'].notna().sum()} valeurs")
        
        # Colonnes prot√©g√©es (ne jamais modifier)
        protected_columns = ['Amount CCYs', 'Amount USD', 'Rate FX', 'Entity', 'Period', 'Date']
        target_columns = ['Nature', 'Descrip', 'Vessel', 'Service', 'Reference']
        
        # Cr√©er les colonnes cibles si elles n'existent pas
        for col in target_columns:
            if col not in df.columns:
                df[col] = ''
                print(f"‚ûï Colonne '{col}' cr√©√©e")
        
        rules_applied = 0
        cells_filled = 0
        
        # üéØ TRI OPTIMIS√â : Priorit√© + Support + Longueur du pattern
        def rule_priority(rule):
            priority = rule.get('priority', 999)  # Plus bas = meilleur
            support = rule.get('support', 0)     # Plus haut = meilleur
            pattern_len = len(rule.get('pattern', ''))  # Plus long = plus sp√©cifique
            
            return (priority, -support, -pattern_len)  # Ordre croissant pour priority, d√©croissant pour autres
        
        sorted_rules = sorted(self.rules, key=rule_priority)
        print(f"üîÑ Application de TOUTES les {len(sorted_rules)} r√®gles dans l'ordre optimal...")
        
        for rule_idx, rule in enumerate(sorted_rules):  # ‚úÖ TOUTES LES R√àGLES
            pattern = rule.get('pattern', '').lower().strip()
            if len(pattern) < 3:
                continue
            
            try:
                # üîß CORRECTION ROBUSTE : G√©rer les DataFrame multiples
                if 'Description' not in df.columns:
                    if rule_idx < 5:  # Afficher seulement les 5 premi√®res erreurs
                        print(f"   ‚ö†Ô∏è R√®gle {rule_idx+1}: Colonne 'Description' introuvable")
                    continue
                
                description_col = df['Description']
                
                # Forcer la conversion en Series si c'est un DataFrame
                if isinstance(description_col, pd.DataFrame):
                    description_series = description_col.iloc[:, 0]  # Prendre la premi√®re colonne
                    if rule_idx < 3:  # Afficher seulement les 3 premi√®res conversions
                        print(f"   üîß R√®gle {rule_idx+1}: DataFrame converti en Series")
                else:
                    description_series = description_col
                
                # V√©rifier que c'est maintenant une Series
                if not isinstance(description_series, pd.Series):
                    if rule_idx < 5:  # Limiter les messages d'erreur
                        print(f"   ‚ö†Ô∏è R√®gle {rule_idx+1}: Type invalide apr√®s conversion (type: {type(description_series)})")
                    continue
                
                # Rechercher le pattern dans Description avec gestion d'erreur
                try:
                    mask = description_series.str.lower().str.contains(
                        re.escape(pattern), na=False, regex=True
                    )
                except Exception as str_error:
                    if rule_idx < 5:  # Limiter les messages d'erreur
                        print(f"   ‚ö†Ô∏è R√®gle {rule_idx+1}: Erreur de recherche pattern - {str_error}")
                    continue
                
                # V√©rifier que mask est bien un boolean Series
                if not isinstance(mask, pd.Series) or mask.dtype != bool:
                    if rule_idx < 5:  # Limiter les messages d'erreur
                        print(f"   ‚ö†Ô∏è R√®gle {rule_idx+1}: Masque invalide")
                    continue
                
                matches_found = mask.sum()
                if matches_found == 0:
                    continue
                
                                # Afficher seulement un r√©sum√© compact
                if rule_idx < 3:  # Afficher seulement les 3 premi√®res r√®gles
                    print(f"üéØ R√®gle {rule_idx+1}: Pattern '{pattern[:30]}...' ‚Üí {matches_found} correspondances")
                elif rule_idx == 3:
                    print(f"üìù Remplissage en cours... (mode silencieux)")
                
                # Appliquer les colonnes fixes SILENCIEUSEMENT
                rule_cells_filled = 0
                for col, value in rule.get('fixed_columns', {}).items():
                    if col in target_columns and col in df.columns:
                        try:
                            # Identifier les cellules vides dans les lignes correspondantes
                            empty_mask = (df[col].isna() | (df[col] == ''))
                            
                            # Combiner le masque de pattern avec le masque de cellules vides
                            final_mask = mask & empty_mask
                            
                            cells_to_fill = final_mask.sum()
                            if cells_to_fill > 0:
                                df.loc[final_mask, col] = value
                                rule_cells_filled += cells_to_fill
                                cells_filled += cells_to_fill
                                # üîá SILENCIEUX : Pas d'affichage d√©taill√©
                        except Exception as col_error:
                            continue  # Mode silencieux pour les erreurs aussi
                
                if rule_cells_filled > 0:
                    rules_applied += 1
                            
            except Exception as e:
                if rule_idx < 5:  # Limiter les messages d'erreur
                    print(f"   ‚ùå Erreur r√®gle {rule_idx+1}: {e}")
                continue
        
        # Afficher un r√©sum√© compact
        if len(sorted_rules) > 10:
            print(f"üìä R√©sum√©: {rules_applied} r√®gles actives sur {len(sorted_rules)} test√©es")
        
        self.stats.update({
            'rules_applied': rules_applied,
            'cells_filled': cells_filled
        })
        
        print(f"üéâ Remplissage termin√©: {rules_applied}/{len(sorted_rules)} r√®gles appliqu√©es, {cells_filled} cellules remplies")
        
        return df

@excel_bp.route('/upload', methods=['POST'])
def upload_file():
    """üì§ Upload et traitement du fichier Excel avec logs complets"""
    print("\n" + "="*60)
    print("üöÄ D√âBUT DU TRAITEMENT EXCEL")
    print("="*60)
    
    try:
        if 'file' not in request.files:
            print("‚ùå Aucun fichier fourni dans la requ√™te")
            return jsonify({'error': 'Aucun fichier fourni'}), 400
        
        file = request.files['file']
        if file.filename == '' or not allowed_file(file.filename):
            print(f"‚ùå Fichier invalide: {file.filename}")
            return jsonify({'error': 'Fichier invalide'}), 400
        
        print(f"üìÅ Fichier re√ßu: {file.filename}")
        
        # Sauvegarder le fichier
        filename = secure_filename(file.filename)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        unique_filename = f"{timestamp}_{filename}"
        filepath = os.path.join(UPLOAD_FOLDER, unique_filename)
        file.save(filepath)
        print(f"üíæ Fichier sauvegard√©: {filepath}")
        
        # Lire et nettoyer les donn√©es avec d√©tection intelligente
        df = read_excel_smart(filepath)
        df = clean_column_names(df)
        
        # üéØ VALIDATION FLEXIBLE - Chercher une colonne similaire
        print("üîç Recherche de la colonne Description...")
        description_col = None
        possible_desc_cols = ['Description', 'description', 'Descrip', 'descrip', 'Desc', 'desc', 
                              'Libelle', 'Libell√©', 'Detail']  # ‚ùå RETIRE 'Transaction'
        
        # üîß CORRECTION : Chercher d'abord une vraie colonne Description
        for col in df.columns:
            col_lower = str(col).lower()
            if col_lower == 'description':  # Correspondance exacte d'abord
                description_col = col
                print(f"‚úÖ Colonne Description exacte trouv√©e: '{col}'")
                break
        
        if description_col is None:
            for col in df.columns:
                if any(desc_name.lower() in str(col).lower() for desc_name in possible_desc_cols):
                    # üîß V√âRIFIER que ce n'est pas une colonne de date
                    if 'date' not in str(col).lower() and 'period' not in str(col).lower():
                        description_col = col
                        print(f"‚úÖ Colonne description trouv√©e: '{col}'")
                        break
        
        if description_col is None:
            # Essayer de trouver une colonne avec du texte
            print("üîç Recherche d'une colonne texte...")
            for col in df.columns:
                if df[col].dtype == 'object':  # Colonne texte
                    # üîß V√âRIFIER que ce n'est pas une colonne de date/p√©riode
                    if 'date' not in str(col).lower() and 'period' not in str(col).lower():
                        sample_values = df[col].dropna().head(3)
                        if len(sample_values) > 0 and all(len(str(val)) > 10 for val in sample_values):
                            description_col = col
                            print(f"‚úÖ Colonne texte d√©tect√©e: '{col}'")
                            break
        
        if description_col is None:
            available_cols = ', '.join(df.columns)
            print(f"‚ùå Aucune colonne Description trouv√©e. Colonnes disponibles: {available_cols}")
            return jsonify({'error': f'Aucune colonne Description trouv√©e. Colonnes disponibles: {available_cols}'}), 400
        
        # Renommer la colonne pour standardiser
        if description_col != 'Description':
            df = df.rename(columns={description_col: 'Description'})
            print(f"üîÑ Colonne renomm√©e: '{description_col}' ‚Üí 'Description'")
        
        # Calculer qualit√© initiale
        initial_empty = df.isna().sum().sum() + (df == '').sum().sum()
        initial_completion = ((df.size - initial_empty) / df.size) * 100
        print(f"üìä Qualit√© initiale: {initial_completion:.1f}% rempli")
        
        # Appliquer les r√®gles
        predictor = RulesPredictor()
        if predictor.load_rules():
            processed_df = predictor.apply_rules(df.copy())
        else:
            print("‚ö†Ô∏è Aucune r√®gle charg√©e, fichier non modifi√©")
            processed_df = df.copy()
        # üìÖ Formatter la colonne Period
        processed_df = format_period_column(processed_df)
        
        # Calculer qualit√© finale
        final_empty = processed_df.isna().sum().sum() + (processed_df == '').sum().sum()
        final_completion = ((processed_df.size - final_empty) / processed_df.size) * 100
        improvement = final_completion - initial_completion
        
        print(f"üìä Qualit√© finale: {final_completion:.1f}% rempli (+{improvement:.1f}%)")
        
        # Sauvegarder avec formatage
        processed_filename = f"processed_{unique_filename}"
        processed_filepath = os.path.join(PROCESSED_FOLDER, processed_filename)
        formatting_success = apply_formatting(processed_df, processed_filepath)
        
        print(f"üíæ Fichier trait√© sauvegard√©: {processed_filename}")
        print("üéâ TRAITEMENT TERMIN√â AVEC SUCC√àS")
        print("="*60)
        
        # üîß CONVERSION POUR JSON : Convertir les types numpy en types Python
        def convert_numpy_types(obj):
            """Convertit les types numpy en types Python pour JSON"""
            if isinstance(obj, (pd.Series, pd.DataFrame)):
                return obj.to_dict()
            elif hasattr(obj, 'item'):  # numpy types
                return obj.item()
            elif isinstance(obj, dict):
                return {key: convert_numpy_types(value) for key, value in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy_types(item) for item in obj]
            else:
                return obj
                
        return jsonify({
            'success': True,
            'message': 'Fichier trait√© avec succ√®s',
            'processed_file': processed_filename,
            'original_file': filename,  # ‚úÖ Ajout du nom original
            'columns_info': {
                'shape': [int(processed_df.shape[0]), int(processed_df.shape[1])],  # ‚úÖ Format attendu
                'columns': list(processed_df.columns),
                'empty_columns': [col for col in processed_df.columns if processed_df[col].isna().all()]
            },
            'changes_applied': {
                'rules_applied': [f"R√®gle {i+1}" for i in range(min(5, int(predictor.stats['rules_applied'])))]  # ‚úÖ Format attendu
            },
            'statistics': {
                'initial_completion': float(round(initial_completion, 2)),
                'final_completion': float(round(final_completion, 2)),
                'improvement': float(round(improvement, 2)),
                'cells_filled': int(predictor.stats['cells_filled']),
                'rules_applied': int(predictor.stats['rules_applied'])
            },
            'formatting_applied': formatting_success
        })
        
    except Exception as e:
        print(f"üí• ERREUR CRITIQUE: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500  # ‚úÖ Ajout du return complet

@excel_bp.route('/download/<filename>')
def download_file(filename):
    """üì• T√©l√©charge un fichier trait√©"""
    try:
        file_path = os.path.join(PROCESSED_FOLDER, filename)
        if not os.path.exists(file_path):
            return jsonify({'error': 'Fichier non trouv√©'}), 404
        return send_file(file_path, as_attachment=True)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@excel_bp.route('/health')
def health_check():
    """üè• V√©rifie l'√©tat du service"""
    predictor = RulesPredictor()
    rules_available = predictor.load_rules()
    
    return jsonify({
        'status': 'healthy',
        'rules_available': rules_available,
        'rules_count': len(predictor.rules) if rules_available else 0,
        'timestamp': datetime.datetime.now().isoformat()
    })