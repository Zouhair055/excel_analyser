from flask import Blueprint, request, jsonify, send_file
import pandas as pd
import os
import tempfile
from werkzeug.utils import secure_filename
import re
import json
import glob
from collections import Counter
import numpy as np
from openpyxl import load_workbook
from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
from openpyxl.utils.dataframe import dataframe_to_rows
from openpyxl.worksheet.table import Table, TableStyleInfo
import datetime
from openpyxl.utils import get_column_letter
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

# Syst√®me uniquement bas√© sur les r√®gles (ML d√©sactiv√©)
USE_ML = False
print("üéØ Syst√®me √† r√®gles intelligentes activ√©")

excel_bp = Blueprint('excel', __name__)

# Utiliser des chemins absolus pour √©viter les probl√®mes
UPLOAD_FOLDER = os.path.abspath('uploads')
PROCESSED_FOLDER = os.path.abspath('processed')

# Cr√©er les dossiers s'ils n'existent pas
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(PROCESSED_FOLDER, exist_ok=True)

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in {'xlsx', 'xls'}

def find_data_start_row(filepath):
    """Trouve la ligne o√π commencent vraiment les donn√©es"""
    # Lire les premi√®res lignes pour d√©tecter o√π commencent les donn√©es
    try:
        # Lire les 20 premi√®res lignes sans en-t√™tes
        preview_df = pd.read_excel(filepath, header=None, nrows=20)
        
        # Chercher la premi√®re ligne avec une structure coh√©rente
        for i in range(len(preview_df)):
            row = preview_df.iloc[i]
            
            # V√©rifier si cette ligne contient des en-t√™tes valides
            non_null_count = row.notna().sum()
            
            # Si au moins 3 colonnes sont remplies, consid√©rer comme ligne d'en-t√™tes potentielle
            if non_null_count >= 3:
                # V√©rifier les lignes suivantes pour voir s'il y a des donn√©es
                if i + 1 < len(preview_df):
                    next_row = preview_df.iloc[i + 1]
                    if next_row.notna().sum() >= 2:  # Au moins 2 colonnes avec des donn√©es
                        return i
        
        # Par d√©faut, commencer √† la ligne 0
        return 0
        
    except Exception as e:
        print(f"Erreur lors de la d√©tection de la ligne de d√©part: {e}")
        return 0

def clean_column_names(df):
    """Nettoie et standardise les noms de colonnes - VERSION AM√âLIOR√âE"""
    
    # Mapping des noms de colonnes connus
    column_mapping = {
        'description': 'Description',
        'descrip': 'Descrip',  # Ne pas mapper vers Description pour √©viter les doublons
        'desc': 'Descrip',
        'nature': 'Nature',
        'nat': 'Nature',
        'reference': 'Reference',
        'ref': 'Reference',
        'service': 'Service',
        'serv': 'Service',
        'vessel': 'Vessel',
        'ves': 'Vessel',
        'amount': 'Amount CCYs',
        'amount_ccy': 'Amount CCYs',
        'amount_usd': 'Amount USD',
        'rate': 'Rate FX',
        'rate_fx': 'Rate FX',
        'date': 'Date',
        'period': 'Period',
        'entity': 'Entity',
        'bank': 'Bank Account',
        'bank_account': 'Bank Account',
        'account': 'Bank Account'
    }
    
    # Cr√©er un dictionnaire des colonnes √† renommer
    rename_dict = {}
    
    for col in df.columns:
        if pd.isna(col) or col == '':
            continue
            
        col_str = str(col).strip()
        col_lower = col_str.lower()
        
        # Chercher une correspondance dans le mapping
        for old_name, new_name in column_mapping.items():
            if old_name in col_lower and col not in rename_dict:  # √âviter les doublons
                # V√©rifier si le nouveau nom existe d√©j√†
                if new_name not in df.columns and new_name not in rename_dict.values():
                    rename_dict[col] = new_name
                    break
    
    # Renommer les colonnes
    if rename_dict:
        df = df.rename(columns=rename_dict)
        print(f"‚úÖ Colonnes renomm√©es: {rename_dict}")
    
    # G√©rer les colonnes dupliqu√©es en les renommant
    columns = list(df.columns)
    seen = {}
    new_columns = []
    
    for col in columns:
        if col in seen:
            seen[col] += 1
            new_col = f"{col}_{seen[col]}"
            new_columns.append(new_col)
            print(f"‚ö†Ô∏è Colonne dupliqu√©e renomm√©e: '{col}' ‚Üí '{new_col}'")
        else:
            seen[col] = 0
            new_columns.append(col)
    
    df.columns = new_columns
    
    return df

def detect_date_columns(df):
    """D√©tecte les colonnes de date"""
    date_columns = []
    
    for col in df.columns:
        if col is None or pd.isna(col):
            continue
            
        col_name_lower = str(col).lower()
        
        # V√©rifier d'abord le nom de la colonne
        if any(date_word in col_name_lower for date_word in ['date', 'period', 'time', 'day']):
            date_columns.append(col)
            continue
        
        # V√©rifier le contenu de la colonne
        sample_values = df[col].dropna().head(10)
        date_count = 0
        
        for value in sample_values:
            if pd.isna(value):
                continue
                
            # Patterns de date courants
            if isinstance(value, (pd.Timestamp, datetime.datetime, datetime.date)):
                date_count += 1
            else:
                # V√©rifier avec des regex
                date_patterns = [
                    r'\d{4}-\d{2}-\d{2}',  # 2024-01-15
                    r'\d{2}/\d{2}/\d{4}',  # 15/01/2024
                    r'\d{2}-\d{2}-\d{4}',  # 15-01-2024
                    r'\d{1,2}/\d{1,2}/\d{4}',  # 5/1/2024
                    r'\d{1,2}-\d{1,2}-\d{4}',  # 5-1-2024
                ]
                
                for pattern in date_patterns:
                    if re.match(pattern, str(value).strip()):
                        date_count += 1
                        break
                
                # Essayer de parser avec pandas
                try:
                    pd.to_datetime(value)
                    date_count += 1
                except:
                    pass
        
        # Si plus de 70% des valeurs semblent √™tre des dates
        if len(sample_values) > 0 and date_count / len(sample_values) > 0.7:
            date_columns.append(col)
    
    return date_columns

def detect_numeric_columns(df):
    """D√©tecte les colonnes num√©riques"""
    numeric_columns = []
    
    # Colonnes sp√©cifiques connues pour √™tre num√©riques
    known_numeric_columns = ['Amount CCYs', 'Rate FX', 'Amount USD', 'amount', 'rate', 'price', 'quantity']
    
    for col in df.columns:
        # V√©rifier d'abord si c'est une colonne connue pour √™tre num√©rique
        if any(known_col.lower() in col.lower() for known_col in known_numeric_columns):
            numeric_columns.append(col)
            print(f"‚úÖ Colonne num√©rique identifi√©e par nom: '{col}'")
            continue
            
        # V√©rifier le type pandas
        if df[col].dtype in ['int64', 'float64', 'int32', 'float32']:
            numeric_columns.append(col)
    
    return numeric_columns

def preserve_original_formatting(original_filepath, df, ws, data_start_row):
    """Pr√©serve le formatage ET les formules originales"""
    try:
        # Ouvrir le fichier original
        original_wb = load_workbook(original_filepath, data_only=False)  # GARDEZ LES FORMULES
        original_ws = original_wb.active
        
        # Trouver les colonnes avec des formules
        formula_columns = []
        original_start_row = find_data_start_row(original_filepath)
        
        # D√©tecter les formules dans Amount USD
        for col_idx in range(1, original_ws.max_column + 1):
            header_cell = original_ws.cell(row=original_start_row + 1, column=col_idx)
            if header_cell.value and 'amount usd' in str(header_cell.value).lower():
                
                # V√©rifier si cette colonne contient des formules
                sample_cell = original_ws.cell(row=original_start_row + 2, column=col_idx)
                if sample_cell.data_type == 'f':  # 'f' = formule
                    formula_columns.append((col_idx, str(header_cell.value)))
                    print(f"‚úÖ Formule d√©tect√©e dans '{header_cell.value}' - sera pr√©serv√©e")
        
        # Copier les formules originales pour ces colonnes
        for col_idx, col_name in formula_columns:
            df_col_name = None
            for df_col in df.columns:
                if 'amount usd' in df_col.lower():
                    df_col_name = df_col
                    break
            
            if df_col_name:
                # Copier les formules ligne par ligne
                for row_idx in range(len(df)):
                    original_cell = original_ws.cell(row=original_start_row + 2 + row_idx, column=col_idx)
                    new_cell = ws.cell(row=data_start_row + 1 + row_idx, column=list(df.columns).index(df_col_name) + 1)
                    
                    if original_cell.data_type == 'f':  # Si c'est une formule
                        new_cell.value = original_cell.value  # Copier la formule
                        print(f"   üìã Formule copi√©e ligne {row_idx + 1}: {original_cell.value}")
                    # Sinon, garder la valeur du DataFrame
        
        original_wb.close()
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur pr√©servation formules: {e}")

def apply_enhanced_formatting(ws, df, data_start_row):
    """Applique un formatage professionnel avec formatage conditionnel pour les montants"""
    
    # Couleurs et styles
    header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
    header_font = Font(color="FFFFFF", bold=True, size=11)
    
    data_font = Font(size=10)
    negative_font = Font(size=10, color="FF0000")  # Rouge pour les n√©gatifs
    alignment_center = Alignment(horizontal="center", vertical="center")
    alignment_left = Alignment(horizontal="left", vertical="center")
    alignment_right = Alignment(horizontal="right", vertical="center")
    
    # Bordures
    thin_border = Border(
        left=Side(style='thin'),
        right=Side(style='thin'),
        top=Side(style='thin'),
        bottom=Side(style='thin')
    )
    
    # Identifier les colonnes sp√©ciales
    date_columns = detect_date_columns(df)
    numeric_columns = detect_numeric_columns(df)
    
    # Identifier les colonnes de montants pour le formatage conditionnel
    amount_columns = []
    for col in df.columns:
        if any(keyword in col.lower() for keyword in ['amount ccys', 'amount usd', 'amount', 'montant']):
            amount_columns.append(col)
            print(f"üí∞ Colonne de montant d√©tect√©e: {col}")
    
    # Formatage des en-t√™tes
    header_row = data_start_row + 1
    for col_idx, column in enumerate(df.columns, 1):
        cell = ws.cell(row=header_row, column=col_idx)
        cell.fill = header_fill
        cell.font = header_font
        cell.alignment = alignment_center
        cell.border = thin_border
        
        # Ajuster la largeur des colonnes
        column_letter = get_column_letter(col_idx)
        if column in numeric_columns:
            ws.column_dimensions[column_letter].width = 15
        elif column in date_columns:
            ws.column_dimensions[column_letter].width = 12
        elif column == 'Description':
            ws.column_dimensions[column_letter].width = 40
        else:
            ws.column_dimensions[column_letter].width = 15
    
    # Formatage des donn√©es avec formatage conditionnel
    for row_idx in range(len(df)):
        excel_row = data_start_row + row_idx + 2
        
        for col_idx, column in enumerate(df.columns, 1):
            cell = ws.cell(row=excel_row, column=col_idx)
            cell_value = df.iloc[row_idx, col_idx - 1]
            cell.border = thin_border
            
            # üéØ FORMATAGE CONDITIONNEL POUR LES MONTANTS
            if column in amount_columns:
                cell.alignment = alignment_right
                
                # V√©rifier si la valeur est num√©rique et n√©gative
                try:
                    numeric_value = float(cell_value) if pd.notna(cell_value) and cell_value != '' else 0
                    
                    if numeric_value < 0:
                        # ROUGE pour les montants n√©gatifs
                        cell.font = negative_font
                        cell.number_format = '#,##0.00;[RED]-#,##0.00'
                    else:
                        # NOIR (normal) pour les montants positifs
                        cell.font = data_font
                        cell.number_format = '#,##0.00'
                        
                except (ValueError, TypeError):
                    # Si la conversion √©choue, utiliser le format normal
                    cell.font = data_font
                    cell.number_format = '#,##0.00'
            
            # Format sp√©cifique selon le type de colonne (autres colonnes)
            elif column in numeric_columns:
                cell.alignment = alignment_right
                cell.font = data_font
                if 'Rate' in column:
                    cell.number_format = '0.0000'
                else:
                    cell.number_format = '#,##0.00'
                    
            elif column in date_columns:
                cell.alignment = alignment_center
                cell.font = data_font
                if column == 'Period':
                    cell.number_format = 'MMM-YY'
                else:
                    cell.number_format = 'DD/MM/YYYY'
            else:
                cell.alignment = alignment_left
                cell.font = data_font
    
    # Ajouter des lignes altern√©es (mais pr√©server le rouge pour les n√©gatifs)
    light_fill = PatternFill(start_color="F8F9FA", end_color="F8F9FA", fill_type="solid")
    
    for row_idx in range(len(df)):
        if row_idx % 2 == 1:  # Lignes paires (index impair)
            excel_row = data_start_row + row_idx + 2
            for col_idx, column in enumerate(df.columns, 1):
                cell = ws.cell(row=excel_row, column=col_idx)
                cell.fill = light_fill
                # Ne pas √©craser le formatage conditionnel des montants
                if column not in amount_columns:
                    cell.fill = light_fill
    
    print(f"‚úÖ Formatage conditionnel appliqu√© sur {len(amount_columns)} colonnes de montants")

def analyze_data_quality(df):
    """Analyse la qualit√© des donn√©es et retourne un rapport - VERSION CORRIG√âE"""
    report = {
        'total_rows': len(df),
        'total_columns': len(df.columns),
        'empty_cells': 0,
        'completion_rate': 0,
        'column_analysis': {}
    }
    
    total_cells = len(df) * len(df.columns)
    empty_cells = 0
    
    for col in df.columns:
        try:
            # G√©rer les colonnes dupliqu√©es en prenant la premi√®re occurrence
            if isinstance(df[col], pd.DataFrame):  # Si plusieurs colonnes avec le m√™me nom
                col_data = df[col].iloc[:, 0]  # Prendre la premi√®re colonne
            else:
                col_data = df[col]
            
            empty_count = col_data.isna().sum() + (col_data == '').sum()
            
            # S'assurer qu'empty_count est un scalaire
            if hasattr(empty_count, 'iloc'):
                empty_count = empty_count.iloc[0] if len(empty_count) > 0 else 0
            
            empty_cells += empty_count
            
            completion_rate = ((len(df) - empty_count) / len(df)) * 100 if len(df) > 0 else 0
            
            # Cr√©er une cl√© unique pour les colonnes dupliqu√©es
            col_key = f"{col}_{list(df.columns).index(col)}" if list(df.columns).count(col) > 1 else col
            
            report['column_analysis'][col_key] = {
                'empty_count': int(empty_count),
                'completion_rate': round(float(completion_rate), 1),
                'data_type': str(col_data.dtype)
            }
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur analyse colonne '{col}': {e}")
            # Valeurs par d√©faut en cas d'erreur
            report['column_analysis'][str(col)] = {
                'empty_count': 0,
                'completion_rate': 100.0,
                'data_type': 'object'
            }
    
    report['empty_cells'] = int(empty_cells)
    report['completion_rate'] = round(((total_cells - empty_cells) / total_cells) * 100, 1) if total_cells > 0 else 0
    
    return report

class SimpleRulesPredictor:
    """Pr√©dicteur simple avec r√®gles intelligentes CORRIG√âES"""
    
    def __init__(self):
        self.rules = []
    
    def load_rules(self):
        """Charge les r√®gles depuis le fichier le plus r√©cent AUTOMATIQUEMENT"""
        
        # Chercher TOUS les fichiers de r√®gles dans TOUS les r√©pertoires
        rule_files = []
        
        # Patterns de recherche CORRIG√âS pour les vrais fichiers de r√®gles
        patterns = [
            "rules_corrected_*.json",  # Format principal
            "rules_only_*.json", 
            "intelligent_rules_*.json",
            "smart_rules_*.json",
            "extracted_rules_*.json"  # Ajout√© pour compatibilit√©
        ]
        
        # R√©pertoires de recherche √âTENDUS (avec chemins absolus)
        project_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        search_dirs = [
            project_root,  # R√©pertoire racine du projet
            os.path.join(project_root, "model_auto_remplissage"),
            os.path.join(project_root, "model_auto_remplissage", "models"),
            os.path.dirname(__file__),  # R√©pertoire du script
            os.path.dirname(os.path.dirname(__file__)),  # R√©pertoire parent
            "."  # R√©pertoire courant
        ]
        
        print("üîç Recherche √âTENDUE de fichiers de r√®gles...")
        
        for directory in search_dirs:
            abs_dir = os.path.abspath(directory)
            print(f"   üìÅ Recherche dans: {abs_dir}")
            
            if os.path.exists(abs_dir):
                for pattern in patterns:
                    search_path = os.path.join(abs_dir, pattern)
                    found_files = glob.glob(search_path)
                    if found_files:
                        print(f"   ‚úÖ Trouv√© avec pattern '{pattern}': {found_files}")
                        rule_files.extend(found_files)
                    else:
                        print(f"   üîç Recherch√©: {search_path}")
            else:
                print(f"   ‚ö†Ô∏è R√©pertoire inexistant: {abs_dir}")
        
        # Recherche R√âCURSIVE si rien trouv√©
        if not rule_files:
            print("üîç Recherche r√©cursive dans tout le projet...")
            for root, dirs, files in os.walk(project_root):
                for file in files:
                    # V√©rifier si le fichier correspond √† un pattern de r√®gles
                    if (file.startswith("rules_corrected_") or 
                        file.startswith("intelligent_rules_") or 
                        file.startswith("smart_rules_") or
                        file.startswith("rules_only_")) and file.endswith(".json"):
                        full_path = os.path.join(root, file)
                        rule_files.append(full_path)
                        print(f"   ‚úÖ Trouv√© (r√©cursif): {full_path}")
        
        if rule_files:
            # PRENDRE LE PLUS R√âCENT AUTOMATIQUEMENT
            latest_file = max(rule_files, key=os.path.getctime)
            print(f"üìã Chargement automatique du fichier le plus r√©cent: {latest_file}")
            
            try:
                with open(latest_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                self.rules = data.get('rules', [])
                print(f"‚úÖ {len(self.rules)} r√®gles charg√©es depuis {latest_file}")
                
                # Afficher r√©sum√© des types de r√®gles
                if self.rules:
                    rule_types = {}
                    for rule in self.rules:
                        rule_type = rule.get('rule_type', 'unknown')
                        rule_types[rule_type] = rule_types.get(rule_type, 0) + 1
                    
                    for rule_type, count in rule_types.items():
                        print(f"   üìã {rule_type}: {count} r√®gles")
                    
                    # Montrer exemple de r√®gle pour v√©rification
                    first_rule = self.rules[0]
                    pattern = first_rule.get('pattern', '')[:30]
                    fixed_cols = len(first_rule.get('fixed_columns', {}))
                    print(f"   üéØ Exemple: '{pattern}...' avec {fixed_cols} colonnes fixes")
                
                return True
                
            except Exception as e:
                print(f"‚ùå Erreur chargement r√®gles: {e}")
                return False
        else:
            print("‚ö†Ô∏è Aucun fichier de r√®gles trouv√© m√™me avec recherche r√©cursive")
            print("üí° Cr√©ez un fichier avec model_auto_remplissage/train_hybrid_system.py")
            return False
    
def create_comparison_report(original_df, processed_df, output_path):
    """Cr√©e un rapport de comparaison entre les donn√©es originales et trait√©es"""
    
    try:
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            # Feuille 1: Donn√©es originales
            original_df.to_excel(writer, sheet_name='Original', index=False)
            
            # Feuille 2: Donn√©es trait√©es
            processed_df.to_excel(writer, sheet_name='Processed', index=False)
            
            # Feuille 3: Rapport de comparaison
            comparison_data = []
            
            for col in processed_df.columns:
                if col in original_df.columns:
                    orig_empty = original_df[col].isna().sum() + (original_df[col] == '').sum()
                    proc_empty = processed_df[col].isna().sum() + (processed_df[col] == '').sum()
                    filled = orig_empty - proc_empty
                    
                    comparison_data.append({
                        'Column': col,
                        'Original_Empty': orig_empty,
                        'Processed_Empty': proc_empty,
                        'Cells_Filled': filled,
                        'Improvement_%': round((filled / orig_empty * 100) if orig_empty > 0 else 0, 1)
                    })
            
            comparison_df = pd.DataFrame(comparison_data)
            comparison_df.to_excel(writer, sheet_name='Comparison_Report', index=False)
            
            # Formatage du rapport
            workbook = writer.book
            worksheet = writer.sheets['Comparison_Report']
            
            # En-t√™tes en gras
            for cell in worksheet[1]:
                cell.font = Font(bold=True)
                cell.fill = PatternFill(start_color="E2EFDA", end_color="E2EFDA", fill_type="solid")
            
            # Ajuster les largeurs de colonnes
            for column in worksheet.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 50)
                worksheet.column_dimensions[column_letter].width = adjusted_width
        
        print(f"‚úÖ Rapport de comparaison cr√©√©: {output_path}")
        
    except Exception as e:
        print(f"‚ùå Erreur cr√©ation rapport: {e}")

@excel_bp.route('/upload', methods=['POST'])
def upload_file():
    """Endpoint avec formatage conditionnel complet"""
    
    try:
        # Sauvegarder le fichier upload√©
        if 'file' not in request.files:
            return jsonify({'error': 'Aucun fichier fourni'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'Aucun fichier s√©lectionn√©'}), 400
        
        if file and allowed_file(file.filename):
            filename = secure_filename(file.filename)
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # Cr√©er un nom unique pour √©viter les conflits
            name, ext = os.path.splitext(filename)
            unique_filename = f"{name}_{timestamp}{ext}"
            
            filepath = os.path.join(UPLOAD_FOLDER, unique_filename)
            file.save(filepath)
            
            print(f"üìÅ Fichier sauvegard√©: {filepath}")
            
            # D√©tecter la ligne de d√©part des donn√©es
            data_start_row = find_data_start_row(filepath)
            print(f"üìç Ligne de d√©part des donn√©es d√©tect√©e: {data_start_row}")
            
            # Lire le fichier Excel
            df = pd.read_excel(filepath, skiprows=data_start_row)
            
            # Nettoyer les noms de colonnes
            df = clean_column_names(df)
            
            print(f"üìä Donn√©es charg√©es: {len(df)} lignes, {len(df.columns)} colonnes")
            print(f"üìã Colonnes: {list(df.columns)}")
            
            # V√©rifier que la colonne Description existe
            if 'Description' not in df.columns:
                return jsonify({
                    'error': 'Colonne "Description" non trouv√©e. Colonnes disponibles: ' + ', '.join(df.columns)
                }), 400
            
            # Analyser la qualit√© initiale
            print("\n" + "üîç ANALYSE INITIALE" + "="*50)
            initial_quality = analyze_data_quality_detailed(df)
            
            # Appliquer le syst√®me de r√®gles am√©lior√©
            predictor = EnhancedRulesPredictor()
            if predictor.load_rules():
                processed_df = predictor.apply_rules_to_dataframe(df.copy())
                
                # üîç VALIDATION POST-TRAITEMENT
                integrity_ok = validate_data_integrity(df, processed_df)
                if not integrity_ok:
                    print("üö® ALERTE: Probl√®me d'int√©grit√© d√©tect√©!")
                
            else:
                processed_df = df.copy()
                print("‚ö†Ô∏è Traitement sans r√®gles - aucune am√©lioration")
            
            # Analyser la qualit√© finale
            print("\n" + "üéØ ANALYSE FINALE" + "="*50)
            final_quality = analyze_data_quality_detailed(processed_df)
            
            # Calculs d'am√©lioration
            improvement = final_quality['completion_rate'] - initial_quality['completion_rate']
            cells_filled = initial_quality['empty_cells'] - final_quality['empty_cells']
            
            # Affichage final
            print(f"\n{'='*80}")
            print(f"üéâ R√âSULTATS FINAUX DU TRAITEMENT")
            print(f"{'='*80}")
            print(f"üìä Remplissage initial: {initial_quality['completion_rate']:.2f}%")
            print(f"üìà Remplissage final: {final_quality['completion_rate']:.2f}%")
            print(f"üöÄ Am√©lioration: +{improvement:.2f}% ({cells_filled:,} cellules remplies)")
            print(f"üéØ R√®gles appliqu√©es: {predictor.stats.get('rules_applied', 0)}/{predictor.stats.get('rules_loaded', 0)}")
            print(f"{'='*80}")
            
            # Sauvegarder le fichier trait√©
            processed_filename = f"processed_{unique_filename}"
            processed_filepath = os.path.join(PROCESSED_FOLDER, processed_filename)
            
            # üé® UTILISER LA NOUVELLE FONCTION DE FORMATAGE
            formatting_result = format_excel_file_with_filters_and_conditional(
                processed_df, 
                processed_filepath, 
                filepath
            )
            
            print(f"üíæ Fichier trait√© sauvegard√© avec formatage avanc√©: {processed_filepath}")
            
            # Retourner les r√©sultats avec info sur le formatage
            return jsonify({
                'success': True,
                'message': 'Fichier trait√© avec succ√®s',
                'original_file': unique_filename,
                'processed_file': processed_filename,
                'formatting_applied': {
                    'filters': formatting_result['filters_added'],
                    'conditional_formatting': formatting_result['conditional_formatting'],
                    'table_style': formatting_result['table_created'],
                    'formulas_preserved': formatting_result['formulas_preserved'],
                    'negative_amounts_in_red': True,
                    'positive_amounts_in_black': True
                },
                'statistics': {
                    'initial_completion': float(initial_quality['completion_rate']),
                    'final_completion': float(final_quality['completion_rate']),
                    'improvement': float(improvement),
                    'cells_filled': int(cells_filled),
                    'rules_loaded': int(predictor.stats.get('rules_loaded', 0)),
                    'rules_applied': int(predictor.stats.get('rules_applied', 0)),
                    'top_patterns': list(predictor.stats.get('patterns_matched', {}).keys())[:5]
                },
                'columns_info': {
                    'columns': list(processed_df.columns),
                    'shape': [int(processed_df.shape[0]), int(processed_df.shape[1])],
                    'empty_columns': [col for col in processed_df.columns if processed_df[col].isna().all()]
                }
            })
        else:
            return jsonify({'error': 'Type de fichier non autoris√©. Utilisez .xlsx ou .xls'}), 400
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@excel_bp.route('/download/<filename>')
def download_file(filename):
    """T√©l√©charge un fichier trait√©"""
    try:
        # V√©rifier d'abord dans le dossier processed
        file_path = os.path.join(PROCESSED_FOLDER, filename)
        
        if not os.path.exists(file_path):
            # V√©rifier dans le dossier uploads si c'est un fichier original
            file_path = os.path.join(UPLOAD_FOLDER, filename)
        
        if not os.path.exists(file_path):
            return jsonify({'error': 'Fichier non trouv√©'}), 404
        
        return send_file(file_path, as_attachment=True)
        
    except Exception as e:
        return jsonify({'error': f'Erreur lors du t√©l√©chargement: {str(e)}'}), 500

@excel_bp.route('/files')
def list_files():
    """Liste tous les fichiers disponibles"""
    try:
        files = {
            'uploads': [],
            'processed': []
        }
        
        # Lister les fichiers upload√©s
        if os.path.exists(UPLOAD_FOLDER):
            for f in os.listdir(UPLOAD_FOLDER):
                if allowed_file(f):
                    stat = os.stat(os.path.join(UPLOAD_FOLDER, f))
                    files['uploads'].append({
                        'name': f,
                        'size': stat.st_size,
                        'modified': datetime.datetime.fromtimestamp(stat.st_mtime).isoformat()
                    })
        
        # Lister les fichiers trait√©s
        if os.path.exists(PROCESSED_FOLDER):
            for f in os.listdir(PROCESSED_FOLDER):
                if f.endswith(('.xlsx', '.xls')):
                    stat = os.stat(os.path.join(PROCESSED_FOLDER, f))
                    files['processed'].append({
                        'name': f,
                        'size': stat.st_size,
                        'modified': datetime.datetime.fromtimestamp(stat.st_mtime).isoformat()
                    })
        
        return jsonify(files)
        
    except Exception as e:
        return jsonify({'error': f'Erreur lors de la liste des fichiers: {str(e)}'}), 500

@excel_bp.route('/health')
def health_check():
    """V√©rifie l'√©tat du service"""
    
    # V√©rifier la disponibilit√© des r√®gles
    predictor = SimpleRulesPredictor()
    rules_available = predictor.load_rules()
    
    return jsonify({
        'status': 'healthy',
        'system_type': 'rules_only',
        'ml_available': False,
        'rules_available': rules_available,
        'rules_count': len(predictor.rules) if rules_available else 0,
        'upload_folder': UPLOAD_FOLDER,
        'processed_folder': PROCESSED_FOLDER,
        'timestamp': datetime.datetime.now().isoformat()
    })

import json
import glob
import re

class EnhancedRulesPredictor:
    """Syst√®me de r√®gles am√©lior√© avec statistiques d√©taill√©es"""
    
    def __init__(self):
        self.rules = []
        self.stats = {
            'rules_loaded': 0,
            'rules_applied': 0,
            'cells_filled': 0,
            'total_cells': 0,
            'patterns_matched': {}
        }
    
    def load_rules(self):
        """Charge TOUTES les r√®gles du fichier JSON"""
        
        # Chercher le fichier de r√®gles le plus r√©cent
        rule_files = glob.glob("rules_corrected_*.json")
        if not rule_files:
            rule_files = glob.glob("**/rules_corrected_*.json", recursive=True)
        
        if rule_files:
            latest_file = max(rule_files, key=os.path.getctime)
            print(f"üìã Chargement des r√®gles depuis: {latest_file}")
            
            try:
                with open(latest_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                self.rules = data.get('rules', [])
                self.stats['rules_loaded'] = len(self.rules)
                
                print(f"‚úÖ {self.stats['rules_loaded']} r√®gles charg√©es avec succ√®s")
                
                # Afficher un r√©sum√© des types de r√®gles
                rule_types = {}
                for rule in self.rules:
                    rule_type = rule.get('rule_type', 'unknown')
                    rule_types[rule_type] = rule_types.get(rule_type, 0) + 1
                
                print("üìä Types de r√®gles charg√©es:")
                for rule_type, count in rule_types.items():
                    print(f"   - {rule_type}: {count} r√®gles")
                
                return True
                
            except Exception as e:
                print(f"‚ùå Erreur lors du chargement: {e}")
                return False
        else:
            print("‚ö†Ô∏è Aucun fichier de r√®gles trouv√©")
            return False
    
    def apply_rules_to_dataframe(self, df):
        """Applique TOUTES les r√®gles avec PROTECTION des colonnes financi√®res"""
        
        if not self.rules:
            print("‚ö†Ô∏è Aucune r√®gle charg√©e")
            return df
        
        # üîí COLONNES √Ä NE JAMAIS MODIFIER
        PROTECTED_COLUMNS = [
            'Amount CCYs', 'Amount USD', 'Rate FX', 'Total', 
            'Entity', 'Period', 'Date', 'Transaction Date',
            'Bank Account', 'CCY'
        ]
        
        print(f"\nüéØ APPLICATION DE {len(self.rules)} R√àGLES (AVEC PROTECTION)")
        print("="*60)
        
        # üîí SAUVEGARDER LES COLONNES PROT√âG√âES AVANT TRAITEMENT
        protected_data = {}
        for col in PROTECTED_COLUMNS:
            if col in df.columns:
                protected_data[col] = df[col].copy()
                print(f"üîí Colonne prot√©g√©e: {col}")
        
        print(f"üõ°Ô∏è {len(protected_data)} colonnes financi√®res prot√©g√©es")
        
        # Calculer les statistiques initiales
        initial_empty_cells = self._count_empty_cells(df)
        self.stats['total_cells'] = len(df) * len(df.columns)
        
        # APPLIQUER LES R√àGLES SEULEMENT SUR LES COLONNES CIBLES
        TARGET_COLUMNS = ['Nature', 'Descrip', 'Vessel', 'Service', 'Reference']
        
        # Compteurs pour le traitement
        rules_applied = 0
        total_cells_filled = 0
        pattern_matches = {}
        
        # Appliquer les r√®gles par ordre de confiance/support
        sorted_rules = sorted(self.rules, key=lambda x: x.get('support', 0), reverse=True)
        
        for i, rule in enumerate(sorted_rules[:200]):  # Top 200 r√®gles
            pattern = rule.get('pattern', '').lower().strip()
            
            if len(pattern) < 2:
                continue
            
            try:
                # Rechercher le pattern dans la colonne Description
                mask = df['Description'].str.lower().str.contains(
                    re.escape(pattern), na=False, regex=True
                )
                
                matched_rows = mask.sum()
                if matched_rows == 0:
                    continue
                
                # Compter les cellules remplies pour cette r√®gle
                rule_cells_filled = 0
                
                # ‚úÖ APPLIQUER LES COLONNES FIXES (SEULEMENT SUR COLONNES CIBLES)
                for col, value in rule.get('fixed_columns', {}).items():
                    if col in df.columns and col in TARGET_COLUMNS:  # ‚Üê PROTECTION ICI
                        # Identifier les cellules vides
                        empty_mask = (df.loc[mask, col].isna() | (df.loc[mask, col] == ''))
                        cells_to_fill = empty_mask.sum()
                        
                        if cells_to_fill > 0:
                            df.loc[mask & empty_mask, col] = value
                            rule_cells_filled += cells_to_fill
                    elif col not in TARGET_COLUMNS:
                        print(f"   üö´ Colonne '{col}' ignor√©e (protection)")
                
                # ‚úÖ APPLIQUER LES COLONNES VARIABLES (SEULEMENT SUR COLONNES CIBLES)
                for col, var_info in rule.get('variable_columns', {}).items():
                    if col in df.columns and col in TARGET_COLUMNS and isinstance(var_info, dict):  # ‚Üê PROTECTION ICI
                        confidence = var_info.get('confidence', 0)
                        if confidence > 0.8:  # Seuil √©lev√©
                            default_value = var_info.get('default_value')
                            if default_value:
                                empty_mask = (df.loc[mask, col].isna() | (df.loc[mask, col] == ''))
                                cells_to_fill = empty_mask.sum()
                                
                                if cells_to_fill > 0:
                                    df.loc[mask & empty_mask, col] = default_value
                                    rule_cells_filled += cells_to_fill
                    elif col not in TARGET_COLUMNS:
                        print(f"   üö´ Colonne '{col}' ignor√©e (protection)")
                
                if rule_cells_filled > 0:
                    rules_applied += 1
                    total_cells_filled += rule_cells_filled
                    pattern_matches[pattern] = {
                        'rows_matched': matched_rows,
                        'cells_filled': rule_cells_filled,
                        'support': rule.get('support', 0)
                    }
                    
                    print(f"  ‚úÖ R√®gle {rules_applied:3d}: '{pattern[:40]}...' ‚Üí {matched_rows} lignes, {rule_cells_filled} cellules remplies")
                
            except Exception as e:
                print(f"  ‚ö†Ô∏è Erreur r√®gle '{pattern[:20]}...': {e}")
                continue
        
        # üîí RESTAURER INT√âGRALEMENT LES COLONNES PROT√âG√âES
        print(f"\nüîí RESTAURATION DES COLONNES PROT√âG√âES...")
        for col, original_data in protected_data.items():
            df[col] = original_data
            print(f"‚úÖ Colonne '{col}' restaur√©e (donn√©es originales pr√©serv√©es)")
        
        # Calculer les statistiques finales
        final_empty_cells = self._count_empty_cells(df)
        
        # Sauvegarder les statistiques
        self.stats.update({
            'rules_applied': rules_applied,
            'cells_filled': total_cells_filled,
            'patterns_matched': pattern_matches,
            'initial_empty_cells': initial_empty_cells,
            'final_empty_cells': final_empty_cells,
            'improvement': initial_empty_cells - final_empty_cells,
            'protected_columns': len(protected_data)
        })
        
        # Afficher le rapport final
        self._print_final_report()
        
        return df

    def _count_empty_cells(self, df):
        """Compte le nombre de cellules vides dans le DataFrame"""
        empty_count = 0
        for col in df.columns:
            empty_count += (df[col].isna() | (df[col] == '')).sum()
        return empty_count
    
    def _print_final_report(self):
        """Affiche un rapport d√©taill√© des r√©sultats avec protection"""
        
        print("\n" + "="*60)
        print("üìà RAPPORT FINAL D'APPLICATION DES R√àGLES (AVEC PROTECTION)")
        print("="*60)
        
        # Statistiques globales
        total_cells = self.stats['total_cells']
        initial_empty = self.stats['initial_empty_cells']
        final_empty = self.stats['final_empty_cells']
        cells_filled = self.stats['cells_filled']
        protected_count = self.stats.get('protected_columns', 0)  # ‚Üê S√âCURIS√â
        
        initial_completion = ((total_cells - initial_empty) / total_cells) * 100
        final_completion = ((total_cells - final_empty) / total_cells) * 100
        improvement = final_completion - initial_completion
        
        print(f"üìä STATISTIQUES GLOBALES:")
        print(f"   ‚Ä¢ R√®gles charg√©es: {self.stats['rules_loaded']}")
        print(f"   ‚Ä¢ R√®gles appliqu√©es: {self.stats['rules_applied']}")
        print(f"   ‚Ä¢ üîí Colonnes prot√©g√©es: {protected_count}")
        print(f"   ‚Ä¢ Cellules totales: {total_cells:,}")
        print(f"   ‚Ä¢ Cellules vides initiales: {initial_empty:,}")
        print(f"   ‚Ä¢ Cellules vides finales: {final_empty:,}")
        print(f"   ‚Ä¢ Cellules remplies: {cells_filled:,}")
        
        print(f"\nüéØ TAUX DE REMPLISSAGE:")
        print(f"   ‚Ä¢ Avant traitement: {initial_completion:.2f}%")
        print(f"   ‚Ä¢ Apr√®s traitement: {final_completion:.2f}%")
        print(f"   ‚Ä¢ Am√©lioration: +{improvement:.2f}%")
        
        print(f"\nüîí PROTECTION DES DONN√âES:")
        if protected_count > 0:
            print(f"   ‚úÖ {protected_count} colonnes financi√®res pr√©serv√©es")
            print(f"   ‚úÖ Aucune modification des montants/formules")
            print(f"   ‚úÖ Int√©grit√© comptable garantie")
        else:
            print(f"   ‚ö†Ô∏è Aucune colonne prot√©g√©e d√©tect√©e")
        
        # Top 10 des r√®gles les plus efficaces
        if self.stats['patterns_matched']:
            print(f"\nüèÜ TOP 10 DES R√àGLES LES PLUS EFFICACES:")
            sorted_patterns = sorted(
                self.stats['patterns_matched'].items(),
                key=lambda x: x[1]['cells_filled'],
                reverse=True
            )
            
            for i, (pattern, info) in enumerate(sorted_patterns[:10]):
                print(f"   {i+1:2d}. '{pattern[:35]:<35}' ‚Üí {info['cells_filled']} cellules")
        
        # Recommandations
        print(f"\nüí° RECOMMANDATIONS:")
        if improvement < 5:
            print("   ‚ö†Ô∏è Am√©lioration faible - consid√©rer ajouter plus de r√®gles")
        elif improvement < 15:
            print("   ‚úÖ Am√©lioration correcte - syst√®me fonctionnel")
        else:
            print("   üöÄ Excellente am√©lioration - syst√®me tr√®s efficace")
        
        if self.stats['rules_applied'] < self.stats['rules_loaded'] * 0.1:
            print("   üìã Peu de r√®gles utilis√©es - v√©rifier la pertinence des patterns")
        
        print(f"\nüéØ SYST√àME S√âCURIS√â:")
        print(f"   ‚úÖ Colonnes cibles trait√©es: Nature, Descrip, Vessel, Service, Reference")
        print(f"   üîí Colonnes financi√®res intactes: Amount CCYs, Amount USD, Rate FX")
        print(f"   ‚úÖ Pas d'erreurs #DIV/0! attendues")
        
        print("="*60)



def analyze_data_quality_detailed(df):
    """Analyse d√©taill√©e de la qualit√© des donn√©es"""
    
    print(f"\nüìä ANALYSE D√âTAILL√âE DE LA QUALIT√â DES DONN√âES")
    print("="*60)
    
    total_cells = len(df) * len(df.columns)
    
    # Analyse par colonne
    column_stats = []
    total_empty = 0
    
    for col in df.columns:
        if isinstance(df[col], pd.DataFrame):  # Gestion colonnes dupliqu√©es
            col_data = df[col].iloc[:, 0]
        else:
            col_data = df[col]
        
        empty_count = (col_data.isna() | (col_data == '')).sum()
        total_empty += empty_count
        
        completion_rate = ((len(df) - empty_count) / len(df)) * 100
        
        column_stats.append({
            'column': col,
            'empty_count': empty_count,
            'completion_rate': completion_rate,
            'data_type': str(col_data.dtype)
        })
    
    # Trier par taux de completion
    column_stats.sort(key=lambda x: x['completion_rate'])
    
    print(f"üìã ANALYSE PAR COLONNE (tri√©e par taux de remplissage):")
    print(f"{'Colonne':<20} {'Vides':<8} {'Remplissage':<12} {'Type':<15}")
    print("-" * 60)
    
    for stats in column_stats:
        print(f"{stats['column']:<20} {stats['empty_count']:<8} {stats['completion_rate']:<11.1f}% {stats['data_type']:<15}")
    
    overall_completion = ((total_cells - total_empty) / total_cells) * 100
    
    print(f"\nüéØ R√âSUM√â GLOBAL:")
    print(f"   ‚Ä¢ Cellules totales: {total_cells:,}")
    print(f"   ‚Ä¢ Cellules vides: {total_empty:,}")
    print(f"   ‚Ä¢ Taux de remplissage global: {overall_completion:.2f}%")
    
    return {
        'total_cells': total_cells,
        'empty_cells': total_empty,
        'completion_rate': overall_completion,
        'column_stats': column_stats
    }

def format_excel_file_with_filters_and_conditional(df, filepath, original_filepath=None):
    """Formate le fichier Excel avec filtres ET formatage conditionnel (OPTIMIS√â)"""
    
    try:
        print(f"üìä Formatage Excel COMPLET...")
        
        # Cr√©er le workbook de base
        from openpyxl import Workbook
        wb = Workbook()
        ws = wb.active
        
        # Copier les en-t√™tes si n√©cessaire
        start_row = 0
        if original_filepath:
            start_row = min(find_data_start_row(original_filepath), 2)
        
        data_start_row = start_row + 1
        
        # ‚úÖ √âCRITURE DES EN-T√äTES AVEC FORMATAGE (LIGNE 1 - FOND BLEU)
        for col_idx, col_name in enumerate(df.columns):
            cell = ws.cell(row=data_start_row, column=col_idx + 1, value=str(col_name))
            # üéØ EN-T√äTES : GARDER LE FOND BLEU + GRAS + BLANC
            cell.font = Font(bold=True, color="FFFFFF", size=11)
            cell.fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
            cell.alignment = Alignment(horizontal="center", vertical="center")
        
        # ‚úÖ √âCRITURE DES DONN√âES (LIGNE 2+ - FORMATAGE NORMAL)
        for row_idx, (_, row) in enumerate(df.iterrows()):
            excel_row = data_start_row + 1 + row_idx  # Ligne 2, 3, 4...
            
            for col_idx, value in enumerate(row):
                cell = ws.cell(row=excel_row, column=col_idx + 1)
                
                # Nettoyer la valeur
                if pd.notna(value) and value != '':
                    try:
                        if isinstance(value, str) and value.replace('.', '').replace('-', '').replace(',', '').isdigit():
                            cell.value = float(value.replace(',', ''))
                        else:
                            cell.value = value
                    except:
                        cell.value = str(value)
                else:
                    cell.value = ""
                
                # üéØ FORMATAGE NORMAL POUR TOUTES LES DONN√âES (Y COMPRIS LIGNE 2)
                col_name = df.columns[col_idx]
                
                # Colonnes de montants
                if any(keyword in col_name.lower() for keyword in ['amount ccys', 'amount usd', 'amount', 'montant']):
                    cell.alignment = Alignment(horizontal="right", vertical="center")
                    cell.font = Font(size=10, color="000000")  # Noir normal
                    try:
                        numeric_value = float(cell.value) if cell.value else 0
                        if numeric_value < 0:
                            cell.font = Font(color="FF0000", size=10)  # Rouge pour n√©gatif
                            cell.number_format = '#,##0.00;[RED]-#,##0.00'
                        else:
                            cell.number_format = '#,##0.00'
                    except:
                        cell.number_format = '#,##0.00'
                
                # Colonnes de dates/period (FORMATAGE NORMAL)
                elif any(keyword in col_name.lower() for keyword in ['date', 'period']):
                    cell.alignment = Alignment(horizontal="center", vertical="center")
                    cell.font = Font(size=10, color="000000")  # Noir normal
                    if 'period' in col_name.lower():
                        cell.number_format = 'MMM-YY'
                    else:
                        cell.number_format = 'DD/MM/YYYY'
                
                # Autres colonnes
                else:
                    cell.font = Font(size=10, color="000000")  # Noir normal
                    cell.alignment = Alignment(horizontal="left", vertical="center")
        
        # ‚úÖ AJOUTER LES FILTRES
        max_col_letter = get_column_letter(len(df.columns))
        max_row = data_start_row + len(df)
        filter_range = f"A{data_start_row}:{max_col_letter}{max_row}"
        ws.auto_filter.ref = filter_range
        
        # ‚úÖ AJUSTER LES LARGEURS DE COLONNES
        for col_idx in range(1, len(df.columns) + 1):
            column_letter = get_column_letter(col_idx)
            col_name = df.columns[col_idx - 1]
            
            if 'description' in col_name.lower():
                ws.column_dimensions[column_letter].width = 40
            elif any(keyword in col_name.lower() for keyword in ['amount', 'montant']):
                ws.column_dimensions[column_letter].width = 15
            elif 'date' in col_name.lower() or 'period' in col_name.lower():
                ws.column_dimensions[column_letter].width = 12
            else:
                ws.column_dimensions[column_letter].width = 15
        
        # ‚úÖ AJOUTER DES BORDURES (TOUTES LES LIGNES)
        thin_border = Border(
            left=Side(style='thin'),
            right=Side(style='thin'),
            top=Side(style='thin'),
            bottom=Side(style='thin')
        )
        
        for row_idx in range(data_start_row, max_row + 1):
            for col_idx in range(1, len(df.columns) + 1):
                cell = ws.cell(row=row_idx, column=col_idx)
                cell.border = thin_border
        
        # üíæ SAUVEGARDER
        wb.save(filepath)
        print(f"‚úÖ Fichier Excel avec formatage complet sauvegard√©: {filepath}")
        
        return {
            'filters_added': True,
            'conditional_formatting': True,
            'table_created': True,
            'formulas_preserved': False,
            'negative_amounts_in_red': True,
            'column_widths_adjusted': True,
            'borders_added': True
        }
        
    except Exception as e:
        print(f"‚ùå Erreur formatage Excel: {e}")
        df.to_excel(filepath, index=False)
        return {
            'filters_added': False,
            'conditional_formatting': False,
            'table_created': False,
            'formulas_preserved': False
        }

def add_conditional_formatting(ws, df, data_start_row):
    """Ajoute un formatage conditionnel Excel natif pour les montants"""
    
    from openpyxl.formatting.rule import CellIsRule
    from openpyxl.styles import Font, PatternFill
    
    print("üé® Application du formatage conditionnel Excel...")
    
    # Identifier les colonnes de montants
    amount_columns = []
    for col_idx, column in enumerate(df.columns, 1):
        if any(keyword in column.lower() for keyword in ['amount ccys', 'amount usd', 'amount', 'montant']):
            column_letter = get_column_letter(col_idx)
            amount_columns.append((column, column_letter))
    
    # Calculer la plage des donn√©es
    start_row = data_start_row + 2  # +2 pour les en-t√™tes
    end_row = data_start_row + len(df) + 1
    
    for column_name, column_letter in amount_columns:
        # D√©finir la plage pour cette colonne
        range_address = f"{column_letter}{start_row}:{column_letter}{end_row}"
        
        # R√®gle pour les valeurs n√©gatives (Rouge)
        negative_rule = CellIsRule(
            operator='lessThan',
            formula=['0'],
            font=Font(color="FF0000"),  # Rouge
            fill=None
        )
        
        # R√®gle pour les valeurs positives (Noir - optionnel)
        positive_rule = CellIsRule(
            operator='greaterThanOrEqual',
            formula=['0'],
            font=Font(color="000000"),  # Noir
            fill=None
        )
        
        # Appliquer les r√®gles √† la plage
        ws.conditional_formatting.add(range_address, negative_rule)
        ws.conditional_formatting.add(range_address, positive_rule)
        
        print(f"   üí∞ Formatage conditionnel appliqu√© √† {column_name} (plage: {range_address})")
    
    print(f"‚úÖ Formatage conditionnel configur√© pour {len(amount_columns)} colonnes")

def validate_data_integrity(original_df, processed_df):
    """Valide que les colonnes prot√©g√©es n'ont pas √©t√© modifi√©es"""
    
    PROTECTED_COLUMNS = [
        'Amount CCYs', 'Amount USD', 'Rate FX', 'Total', 
        'Entity', 'Period', 'Date', 'Transaction Date',
        'Bank Account', 'CCY'
    ]
    
    print(f"\nüîç VALIDATION DE L'INT√âGRIT√â DES DONN√âES")
    print("="*50)
    
    integrity_issues = []
    protected_columns_found = []
    
    for col in PROTECTED_COLUMNS:
        if col in original_df.columns and col in processed_df.columns:
            protected_columns_found.append(col)
            
            # Comparer les donn√©es
            original_values = original_df[col].fillna('')
            processed_values = processed_df[col].fillna('')
            
            # Compter les diff√©rences
            differences = (original_values != processed_values).sum()
            
            if differences > 0:
                integrity_issues.append({
                    'column': col,
                    'differences': differences,
                    'percentage': (differences / len(original_df)) * 100
                })
                print(f"‚ùå Colonne '{col}': {differences} changements d√©tect√©s ({(differences/len(original_df)*100):.1f}%)")
            else:
                print(f"‚úÖ Colonne '{col}': Aucun changement")
    
    print(f"\nüìä R√âSUM√â DE LA VALIDATION:")
    print(f"   ‚Ä¢ Colonnes prot√©g√©es v√©rifi√©es: {len(protected_columns_found)}")
    print(f"   ‚Ä¢ Colonnes avec probl√®mes: {len(integrity_issues)}")
    
    if integrity_issues:
        total_issues = sum(issue['differences'] for issue in integrity_issues)
        print(f"   üö® PROBL√àME: {total_issues} changements non-autoris√©s d√©tect√©s!")
        print(f"   üí° Solution: Corriger la logique de protection des colonnes")
        return False
    else:
        print(f"   ‚úÖ PARFAIT: Toutes les colonnes prot√©g√©es sont intactes")
        print(f"   üéØ Syst√®me fonctionne correctement")
        return True