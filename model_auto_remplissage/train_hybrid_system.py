"""
üéØ ENTRA√éNEMENT R√àGLES INTELLIGENTES CORRIG√â
Prend en compte TOUTES les valeurs, m√™me les constantes
"""
import os
import pandas as pd
import json
from datetime import datetime
from collections import defaultdict, Counter
import re

def load_training_data():
    """Charge les donn√©es d'entra√Ænement"""
    possible_paths = [
        "training_data.xlsx",
        "model_auto_remplissage/training_data.xlsx",
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            print(f"üìä Chargement: {path}")
            df = pd.read_excel(path, skiprows=7)
            df = df.dropna(how='all')
            print(f"‚úÖ {len(df)} lignes charg√©es")
            return df
    
    print("‚ùå Fichier training_data.xlsx non trouv√©")
    return None

def extract_intelligent_rules_corrected(df):
    """Extrait les r√®gles intelligentes CORRIG√âES"""
    print("üîç Extraction des r√®gles intelligentes corrig√©es...")
    
    rules = []
    pattern_groups = defaultdict(list)
    
    # Grouper par patterns de Description
    for idx, row in df.iterrows():
        desc = str(row.get('Description', '')).lower().strip()
        if len(desc) > 5:  # Descriptions significatives
            signature = {}
            for col in ['Nature', 'Descrip', 'Vessel', 'Service', 'Reference']:
                if col in df.columns:
                    value = str(row.get(col, '')).strip()
                    # ‚úÖ CORRECTION: Prendre toutes les valeurs, m√™me "N/A"
                    if value and value != 'nan' and value != '':
                        signature[col] = value
                    else:
                        signature[col] = ''  # Valeur vide
            
            pattern_groups[desc].append(signature)
    
    # Analyser chaque pattern
    for desc_pattern, signatures in pattern_groups.items():
        if len(signatures) >= 3:  # Minimum 3 occurrences
            rule = {
                'pattern': desc_pattern,
                'support': len(signatures),
                'rule_type': 'complete_fill',
                'fixed_columns': {},
                'variable_columns': {},
                'global_confidence': 0
            }
            
            confidences = []
            
            for col in ['Nature', 'Descrip', 'Vessel', 'Service', 'Reference']:
                values = [sig.get(col, '') for sig in signatures]
                # ‚úÖ CORRECTION: Inclure toutes les valeurs non vides (m√™me "N/A")
                non_empty = [v for v in values if v]
                
                if non_empty:
                    value_counts = Counter(non_empty)
                    most_common, count = value_counts.most_common(1)[0]
                    confidence = count / len(non_empty)
                    
                    # ‚úÖ CORRECTION: Seuils ajust√©s
                    if confidence >= 0.85:  # Haute confiance -> colonne fixe
                        rule['fixed_columns'][col] = most_common
                        confidences.append(confidence)
                    elif confidence >= 0.65:  # Confiance mod√©r√©e -> colonne variable
                        rule['variable_columns'][col] = {
                            'default_value': most_common,
                            'confidence': confidence
                        }
                        confidences.append(confidence)
            
            # Calculer confiance globale
            if confidences:
                rule['global_confidence'] = sum(confidences) / len(confidences)
                
                # D√©terminer le type de r√®gle
                if len(rule['fixed_columns']) >= 2:  # Au moins 2 colonnes fixes
                    rule['rule_type'] = 'complete_fill'
                elif len(rule['fixed_columns']) >= 1:
                    rule['rule_type'] = 'hybrid_fill'
                else:
                    rule['rule_type'] = 'conditional_fill'
                
                rules.append(rule)
    
    # Trier par confiance et support
    rules.sort(key=lambda r: (r['global_confidence'], r['support']), reverse=True)
    
    print(f"‚úÖ {len(rules)} r√®gles intelligentes extraites")
    return rules

def analyze_pattern_details(df, pattern, max_examples=10):
    """Analyse d√©taill√©e d'un pattern pour debug"""
    print(f"\nüîç Analyse d√©taill√©e du pattern: '{pattern}'")
    
    # Trouver toutes les lignes avec ce pattern
    mask = df['Description'].str.lower().str.contains(re.escape(pattern.lower()), na=False)
    matching_rows = df[mask]
    
    print(f"üìä {len(matching_rows)} lignes trouv√©es")
    
    if len(matching_rows) > 0:
        print("üìã Exemples:")
        for idx, (_, row) in enumerate(matching_rows.head(max_examples).iterrows()):
            print(f"  {idx+1}. Nature='{row.get('Nature', '')}', Descrip='{row.get('Descrip', '')}', Vessel='{row.get('Vessel', '')}', Service='{row.get('Service', '')}', Reference='{row.get('Reference', '')}'")
        
        # Analyser la distribution des valeurs
        print("\nüìä Distribution des valeurs:")
        for col in ['Nature', 'Descrip', 'Vessel', 'Service', 'Reference']:
            if col in matching_rows.columns:
                values = matching_rows[col].fillna('').astype(str)
                value_counts = values.value_counts()
                print(f"  {col}:")
                for value, count in value_counts.head(3).items():
                    percentage = (count / len(matching_rows)) * 100
                    print(f"    '{value}': {count} fois ({percentage:.1f}%)")

def save_rules_with_analysis(rules, df):
    """Sauvegarde les r√®gles avec analyse d√©taill√©e"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"rules_corrected_{timestamp}.json"
    
    # Analyser quelques patterns pour v√©rification
    print("\nüîç ANALYSE DES TOP R√àGLES:")
    for i, rule in enumerate(rules[:3]):
        pattern = rule['pattern']
        analyze_pattern_details(df, pattern, max_examples=5)
    
    rules_data = {
        'extraction_time': datetime.now().isoformat(),
        'total_rules': len(rules),
        'system_type': 'rules_corrected',
        'extraction_method': 'include_all_values_including_constants',
        'rules': rules
    }
    
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(rules_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nüíæ R√®gles corrig√©es sauvegard√©es: {filename}")
        return filename
        
    except Exception as e:
        print(f"‚ùå Erreur sauvegarde: {e}")
        return None

def main():
    """Fonction principale CORRIG√âE"""
    print("üöÄ ENTRA√éNEMENT R√àGLES INTELLIGENTES CORRIG√âES")
    print("=" * 60)
    print("Mode: Extraction COMPL√àTE avec valeurs constantes")
    print()
    
    # 1. Charger donn√©es
    df = load_training_data()
    if df is None:
        return
    
    # 2. Extraire r√®gles intelligentes corrig√©es
    rules = extract_intelligent_rules_corrected(df)
    
    # 3. Sauvegarder avec analyse
    rules_file = save_rules_with_analysis(rules, df)
    
    # 4. R√©sum√©
    print("\n" + "=" * 60)
    print("üéâ EXTRACTION CORRIG√âE TERMIN√âE!")
    print(f"‚úÖ {len(rules)} r√®gles intelligentes extraites")
    print(f"üíæ Fichier: {rules_file}")
    
    # 5. Exemples de r√®gles avec d√©tails
    print("\nüìã TOP 5 R√àGLES CORRIG√âES:")
    for i, rule in enumerate(rules[:5], 1):
        pattern = rule['pattern'][:40]
        support = rule['support']
        confidence = rule['global_confidence']
        fixed_cols = rule.get('fixed_columns', {})
        variable_cols = rule.get('variable_columns', {})
        
        print(f"  {i}. Pattern: '{pattern}...'")
        print(f"     Support: {support}, Confiance: {confidence:.2f}")
        print(f"     Colonnes fixes: {list(fixed_cols.keys())}")
        if fixed_cols:
            for col, val in list(fixed_cols.items())[:3]:  # Top 3 colonnes
                print(f"       {col} = '{val}'")
        print()
    
    print("üöÄ Syst√®me de r√®gles corrig√© pr√™t!")
    print("Test: python src/main.py")

if __name__ == "__main__":
    main()

# Ajouter √† la fin de src/routes/excel.py

class SimpleRulesPredictor:
    """Pr√©dicteur simple avec r√®gles intelligentes CORRIG√âES"""
    
    def __init__(self):
        self.rules = []
    
    def load_rules(self):
        """Charge les r√®gles depuis le fichier le plus r√©cent"""
        import glob
        
        # Chercher les fichiers de r√®gles (priorit√© aux corrig√©es)
        rule_files = (
            glob.glob("rules_corrected_*.json") + 
            glob.glob("rules_only_*.json") + 
            glob.glob("intelligent_rules_*.json")
        )
        
        if rule_files:
            # Prendre le plus r√©cent
            latest_file = max(rule_files, key=os.path.getctime)
            print(f"üìã Chargement des r√®gles corrig√©es: {latest_file}")
            
            try:
                with open(latest_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                self.rules = data.get('rules', [])
                print(f"‚úÖ {len(self.rules)} r√®gles corrig√©es charg√©es")
                
                # Afficher r√©sum√©
                rule_types = {}
                for rule in self.rules:
                    rule_type = rule.get('rule_type', 'unknown')
                    rule_types[rule_type] = rule_types.get(rule_type, 0) + 1
                
                for rule_type, count in rule_types.items():
                    print(f"   üìã {rule_type}: {count} r√®gles")
                
                # Montrer exemple de r√®gle "comfort"
                comfort_rules = [r for r in self.rules if 'comfort' in r.get('pattern', '').lower()]
                if comfort_rules:
                    print(f"\nüéØ Exemple r√®gle 'comfort':")
                    rule = comfort_rules[0]
                    for col, val in rule.get('fixed_columns', {}).items():
                        print(f"   {col} = '{val}'")
                
                return True
                
            except Exception as e:
                print(f"‚ùå Erreur chargement r√®gles: {e}")
                return False
        else:
            print("‚ö†Ô∏è Aucun fichier de r√®gles trouv√©")
            return False
    
    def apply_rules_to_dataframe(self, df):
        """Applique les r√®gles corrig√©es au DataFrame"""
        if not self.rules:
            print("‚ö†Ô∏è Aucune r√®gle charg√©e")
            return df
        
        print(f"üéØ Application de {len(self.rules)} r√®gles corrig√©es...")
        
        # Suivre les modifications
        total_filled = 0
        applied_rules = 0
        
        # Prendre les top 100 r√®gles pour performance
        for rule in self.rules[:100]:
            pattern = rule.get('pattern', '')
            
            if len(pattern) < 3:
                continue
            
            try:
                # Trouver les lignes qui correspondent au pattern
                mask = df['Description'].str.lower().str.contains(
                    re.escape(pattern.lower()), na=False, regex=True
                )
                
                if mask.sum() == 0:
                    continue
                
                rule_filled = 0
                
                # Appliquer TOUTES les colonnes fixes (y compris "N/A")
                for col, value in rule.get('fixed_columns', {}).items():
                    if col in df.columns:
                        # Identifier les cellules vides
                        empty_mask = (df.loc[mask, col].isna() | (df.loc[mask, col] == ''))
                        
                        if empty_mask.sum() > 0:
                            df.loc[mask & empty_mask, col] = value
                            rule_filled += empty_mask.sum()
                
                # Appliquer les colonnes variables (haute confiance seulement)
                for col, var_info in rule.get('variable_columns', {}).items():
                    if col in df.columns and isinstance(var_info, dict):
                        confidence = var_info.get('confidence', 0)
                        if confidence > 0.8:  # Seuil √©lev√©
                            default_value = var_info.get('default_value')
                            if default_value:
                                empty_mask = (df.loc[mask, col].isna() | (df.loc[mask, col] == ''))
                                
                                if empty_mask.sum() > 0:
                                    df.loc[mask & empty_mask, col] = default_value
                                    rule_filled += empty_mask.sum()
                
                if rule_filled > 0:
                    applied_rules += 1
                    total_filled += rule_filled
                    print(f"  ‚úÖ R√®gle '{pattern[:30]}...' ‚Üí {rule_filled} cellules remplies")
                
            except Exception as e:
                print(f"  ‚ö†Ô∏è Erreur r√®gle '{pattern[:20]}...': {e}")
                continue
        
        print(f"‚úÖ R√©sultat: {applied_rules} r√®gles appliqu√©es, {total_filled} cellules remplies")
        return df

def apply_rules(df):
    """Version CORRIG√âE - R√®gles intelligentes avec valeurs constantes"""
    print("üîß Application des r√®gles intelligentes CORRIG√âES...")

    try:
        # Utiliser le syst√®me de r√®gles corrig√©
        predictor = SimpleRulesPredictor()
        
        # Charger les r√®gles corrig√©es
        if predictor.load_rules():
            # Appliquer les r√®gles
            df_result = predictor.apply_rules_to_dataframe(df.copy())
            return df_result
        else:
            print("‚ùå Impossible de charger les r√®gles")
            return df.copy()
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur r√®gles corrig√©es: {e}")
        return df.copy()