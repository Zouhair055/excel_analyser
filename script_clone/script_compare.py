import pandas as pd
import os
from datetime import datetime
import tkinter as tk
from tkinter import filedialog

class TrainingVsOutputComparator:
    """Compare le fichier d'entraÃ®nement (vraies valeurs) avec la sortie du systÃ¨me"""
    
    def __init__(self):
        self.target_columns = ['Nature', 'Descrip', 'Vessel', 'Service', 'Reference']
        
    def select_files_gui(self):
        """SÃ©lection des fichiers avec des labels corrects"""
        
        root = tk.Tk()
        root.withdraw()
        
        print("ğŸ¯ COMPARAISON ENTRAÃNEMENT vs SORTIE SYSTÃˆME")
        print("=" * 60)
        print("ğŸ“‹ Workflow:")
        print("   1. Fichier d'entraÃ®nement = vraies valeurs complÃ¨tes")
        print("   2. Fichier de sortie = colonnes remplies par le systÃ¨me")
        print("   3. Comparaison = performance du systÃ¨me de rÃ¨gles")
        print()
        
        # SÃ©lection fichier d'entraÃ®nement (vraies valeurs)
        print("ğŸ“ SÃ©lection du fichier D'ENTRAÃNEMENT (vraies valeurs)...")
        training_file = filedialog.askopenfilename(
            title="ğŸ“ Fichier d'EntraÃ®nement (avec VRAIES valeurs)",
            filetypes=[("Fichiers Excel", "*.xlsx *.xls"), ("Tous les fichiers", "*.*")]
        )
        
        if not training_file:
            print("âŒ Aucun fichier d'entraÃ®nement sÃ©lectionnÃ©")
            root.destroy()
            return None, None
        
        print(f"âœ… Fichier d'entraÃ®nement: {os.path.basename(training_file)}")
        
        # SÃ©lection fichier de sortie (rempli par le systÃ¨me)
        print("\nğŸ“ SÃ©lection du fichier de SORTIE (rempli par le systÃ¨me)...")
        output_file = filedialog.askopenfilename(
            title="ğŸ“ Fichier de Sortie (rempli par le systÃ¨me)",
            filetypes=[("Fichiers Excel", "*.xlsx *.xls"), ("Tous les fichiers", "*.*")]
        )
        
        if not output_file:
            print("âŒ Aucun fichier de sortie sÃ©lectionnÃ©")
            root.destroy()
            return None, None
        
        print(f"âœ… Fichier de sortie: {os.path.basename(output_file)}")
        
        root.destroy()
        return training_file, output_file
    
    def find_data_start_row(self, filepath):
        """Trouve oÃ¹ commencent les donnÃ©es (mÃªme logique que l'app)"""
        try:
            df_preview = pd.read_excel(filepath, header=None, nrows=15)
            
            for idx, row in df_preview.iterrows():
                row_str = ' '.join([str(cell) for cell in row if pd.notna(cell)]).lower()
                if 'description' in row_str:
                    return idx
            
            for idx, row in df_preview.iterrows():
                non_null_count = row.notna().sum()
                if non_null_count >= 5:
                    row_str = ' '.join([str(cell) for cell in row if pd.notna(cell)]).lower()
                    keywords = ['date', 'amount', 'entity', 'nature', 'vessel', 'service', 'period']
                    if any(keyword in row_str for keyword in keywords):
                        return idx
            return 0
        except Exception:
            return 0
    
    def read_excel_smart(self, filepath):
        """Lecture intelligente du fichier"""
        start_row = self.find_data_start_row(filepath)
        df = pd.read_excel(filepath, header=start_row)
        df.columns = [str(col).strip() if pd.notna(col) else f'Unnamed_{i}' for i, col in enumerate(df.columns)]
        df = df.dropna(how='all')
        return df
    
    def compare_training_vs_output(self, training_file, output_file):
        """Compare l'entraÃ®nement (vraies valeurs) avec la sortie du systÃ¨me"""
        
        print("\n" + "ğŸ¯ ANALYSE DE PERFORMANCE DU SYSTÃˆME" + "="*30)
        print(f"ğŸ“š Fichier d'entraÃ®nement: {os.path.basename(training_file)}")
        print(f"ğŸ¤– Fichier de sortie: {os.path.basename(output_file)}")
        
        try:
            # Charger les fichiers
            df_training = self.read_excel_smart(training_file)
            df_output = self.read_excel_smart(output_file)
            
            print(f"\nğŸ“Š Structure des fichiers:")
            print(f"   â€¢ EntraÃ®nement: {len(df_training)} lignes, {len(df_training.columns)} colonnes")
            print(f"   â€¢ Sortie: {len(df_output)} lignes, {len(df_output.columns)} colonnes")
            
            # VÃ©rifier que les structures correspondent
            if len(df_training) != len(df_output):
                print("âš ï¸ Nombre de lignes diffÃ©rent - alignement des fichiers")
                min_rows = min(len(df_training), len(df_output))
                df_training = df_training.head(min_rows)
                df_output = df_output.head(min_rows)
            
            # Analyser chaque colonne cible
            self._analyze_system_performance(df_training, df_output)
            
            # VÃ©rifier que les autres colonnes n'ont pas changÃ©
            self._verify_unchanged_columns(df_training, df_output)
            
            # Rapport final de performance
            self._print_performance_report()
            
        except Exception as e:
            print(f"âŒ Erreur: {e}")
            import traceback
            traceback.print_exc()
    
    def _analyze_system_performance(self, df_training, df_output):
        """Analyse la performance du systÃ¨me pour chaque colonne"""
        
        print("\n" + "ğŸ¯ PERFORMANCE PAR COLONNE CIBLE" + "="*35)
        
        self.performance_stats = {}
        self.total_correct = 0
        self.total_predicted = 0
        self.total_should_predict = 0
        
        for column in self.target_columns:
            print(f"\nğŸ“ Analyse de la colonne: {column}")
            print("-" * 50)
            
            if column not in df_training.columns:
                print(f"âŒ Colonne '{column}' manquante dans l'entraÃ®nement")
                continue
                
            if column not in df_output.columns:
                print(f"âŒ Colonne '{column}' manquante dans la sortie")
                continue
            
            # Statistiques pour cette colonne
            correct_predictions = 0
            total_predictions = 0
            false_positives = 0
            missed_predictions = 0
            
            print(f"ğŸ“Š Ã‰chantillon de comparaison (10 premiÃ¨res lignes):")
            print(f"{'Ligne':<6} {'Vraie Valeur':<25} {'PrÃ©diction':<25} {'RÃ©sultat':<15}")
            print("-" * 75)
            
            for idx in range(min(len(df_training), 10)):
                true_val = self._normalize_value(df_training.iloc[idx][column])
                pred_val = self._normalize_value(df_output.iloc[idx][column])
                
                if true_val != '' and pred_val != '':
                    # Le systÃ¨me a prÃ©dit quelque chose pour une vraie valeur
                    if true_val == pred_val:
                        result = "âœ… CORRECT"
                        correct_predictions += 1
                    else:
                        result = "âŒ INCORRECT"
                        false_positives += 1
                    total_predictions += 1
                    print(f"{idx+1:<6} {true_val[:24]:<25} {pred_val[:24]:<25} {result:<15}")
                    
                elif true_val != '' and pred_val == '':
                    # Le systÃ¨me a ratÃ© une valeur qu'il aurait dÃ» prÃ©dire
                    result = "âš ï¸ RATÃ‰"
                    missed_predictions += 1
                    if idx < 5:  # Afficher seulement les 5 premiÃ¨res
                        print(f"{idx+1:<6} {true_val[:24]:<25} {'(vide)':<25} {result:<15}")
                
                elif true_val == '' and pred_val != '':
                    # Le systÃ¨me a prÃ©dit lÃ  oÃ¹ il n'y avait rien
                    result = "ğŸ”„ NOUVEAU"
                    total_predictions += 1
                    if idx < 3:  # Afficher seulement les 3 premiÃ¨res
                        print(f"{idx+1:<6} {'(vide)':<25} {pred_val[:24]:<25} {result:<15}")
            
            # Calculer les statistiques complÃ¨tes
            total_correct_for_col = 0
            total_predicted_for_col = 0
            total_should_predict_for_col = 0
            total_missed_for_col = 0
            
            for idx in range(len(df_training)):
                true_val = self._normalize_value(df_training.iloc[idx][column])
                pred_val = self._normalize_value(df_output.iloc[idx][column])
                
                if true_val != '':
                    total_should_predict_for_col += 1
                    
                if pred_val != '':
                    total_predicted_for_col += 1
                    
                if true_val != '' and pred_val == true_val:
                    total_correct_for_col += 1
                    
                if true_val != '' and pred_val == '':
                    total_missed_for_col += 1
            
            # MÃ©triques de performance
            accuracy = (total_correct_for_col / total_should_predict_for_col * 100) if total_should_predict_for_col > 0 else 0
            precision = (total_correct_for_col / total_predicted_for_col * 100) if total_predicted_for_col > 0 else 0
            recall = (total_correct_for_col / total_should_predict_for_col * 100) if total_should_predict_for_col > 0 else 0
            
            print(f"\nğŸ“Š MÃ©triques pour {column}:")
            print(f"   â€¢ Valeurs Ã  prÃ©dire: {total_should_predict_for_col}")
            print(f"   â€¢ PrÃ©dictions faites: {total_predicted_for_col}")
            print(f"   â€¢ PrÃ©dictions correctes: {total_correct_for_col}")
            print(f"   â€¢ Valeurs ratÃ©es: {total_missed_for_col}")
            print(f"   â€¢ ğŸ¯ PrÃ©cision: {accuracy:.1f}% (bonnes rÃ©ponses/total Ã  prÃ©dire)")
            print(f"   â€¢ ğŸ” Rappel: {recall:.1f}% (bonnes rÃ©ponses/total Ã  prÃ©dire)")
            print(f"   â€¢ âš¡ EfficacitÃ©: {precision:.1f}% (bonnes rÃ©ponses/prÃ©dictions faites)")
            
            # Stocker les stats
            self.performance_stats[column] = {
                'total_should_predict': total_should_predict_for_col,
                'total_predicted': total_predicted_for_col,
                'correct_predictions': total_correct_for_col,
                'missed': total_missed_for_col,
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall
            }
            
            # Mettre Ã  jour les totaux
            self.total_correct += total_correct_for_col
            self.total_predicted += total_predicted_for_col
            self.total_should_predict += total_should_predict_for_col
    
    def _verify_unchanged_columns(self, df_training, df_output):
        """VÃ©rifie que les autres colonnes n'ont pas changÃ©"""
        
        print("\n" + "ğŸ”’ VÃ‰RIFICATION DES AUTRES COLONNES" + "="*25)
        
        # Colonnes qui ne doivent pas changer
        common_cols = set(df_training.columns) & set(df_output.columns)
        other_cols = [col for col in common_cols if col not in self.target_columns]
        
        changes_detected = 0
        
        for col in other_cols:
            col_changes = 0
            for idx in range(len(df_training)):
                train_val = self._normalize_value(df_training.iloc[idx][col])
                out_val = self._normalize_value(df_output.iloc[idx][col])
                
                if train_val != out_val:
                    col_changes += 1
            
            if col_changes > 0:
                changes_detected += col_changes
                print(f"   âš ï¸ {col}: {col_changes} changements dÃ©tectÃ©s")
        
        if changes_detected == 0:
            print("   âœ… Parfait! Aucune colonne non-cible n'a Ã©tÃ© modifiÃ©e")
        else:
            print(f"   ğŸš¨ PROBLÃˆME: {changes_detected} changements dans les colonnes non-cibles")
        
        self.other_columns_stable = changes_detected == 0
    
    def _normalize_value(self, value):
        """Normalise une valeur"""
        if pd.isna(value) or value is None:
            return ''
        return str(value).strip()
    
    def _print_performance_report(self):
        """Rapport final de performance du systÃ¨me"""
        
        print("\n" + "="*80)
        print("ğŸ“Š RAPPORT DE PERFORMANCE FINAL DU SYSTÃˆME")
        print("="*80)
        
        # Performance globale
        overall_accuracy = (self.total_correct / self.total_should_predict * 100) if self.total_should_predict > 0 else 0
        overall_precision = (self.total_correct / self.total_predicted * 100) if self.total_predicted > 0 else 0
        
        print(f"ğŸ¯ PERFORMANCE GLOBALE:")
        print(f"   â€¢ Total de valeurs Ã  prÃ©dire: {self.total_should_predict:,}")
        print(f"   â€¢ Total de prÃ©dictions faites: {self.total_predicted:,}")
        print(f"   â€¢ Total de prÃ©dictions correctes: {self.total_correct:,}")
        print(f"   â€¢ ğŸ“Š PrÃ©cision gÃ©nÃ©rale: {overall_accuracy:.1f}%")
        print(f"   â€¢ âš¡ EfficacitÃ© gÃ©nÃ©rale: {overall_precision:.1f}%")
        
        # Performance par colonne
        print(f"\nğŸ“‹ PERFORMANCE PAR COLONNE:")
        print(f"{'Colonne':<12} {'Ã€ PrÃ©dire':<10} {'PrÃ©dites':<10} {'Correctes':<10} {'PrÃ©cision':<10}")
        print("-" * 60)
        
        for col, stats in self.performance_stats.items():
            print(f"{col:<12} {stats['total_should_predict']:<10} {stats['total_predicted']:<10} {stats['correct_predictions']:<10} {stats['accuracy']:<9.1f}%")
        
        # Classement des colonnes par performance
        sorted_cols = sorted(self.performance_stats.items(), key=lambda x: x[1]['accuracy'], reverse=True)
        
        print(f"\nğŸ† CLASSEMENT PAR PERFORMANCE:")
        for i, (col, stats) in enumerate(sorted_cols, 1):
            emoji = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else "ğŸ“Š"
            print(f"   {emoji} {i}. {col}: {stats['accuracy']:.1f}% de prÃ©cision")
        
        # StabilitÃ© des autres colonnes
        print(f"\nğŸ”’ STABILITÃ‰ DES AUTRES COLONNES:")
        if self.other_columns_stable:
            print("   âœ… Toutes les autres colonnes sont stables")
        else:
            print("   âŒ Certaines colonnes non-cibles ont Ã©tÃ© modifiÃ©es")
        
        # Verdict final et recommandations
        print(f"\nğŸ’¡ VERDICT ET RECOMMANDATIONS:")
        
        if overall_accuracy >= 90:
            print("   ğŸ‰ EXCELLENT! Le systÃ¨me de rÃ¨gles fonctionne trÃ¨s bien")
            print("   âœ… Performance Ã©levÃ©e, systÃ¨me prÃªt pour la production")
        elif overall_accuracy >= 70:
            print("   ğŸ‘ BON! Performance satisfaisante")
            print("   ğŸ”§ Quelques ajustements de rÃ¨gles pourraient amÃ©liorer")
        elif overall_accuracy >= 50:
            print("   âš ï¸ MOYEN! Performance modÃ©rÃ©e")
            print("   ğŸ› ï¸ RÃ©vision des rÃ¨gles recommandÃ©e")
        else:
            print("   ğŸš¨ FAIBLE! Performance insuffisante")
            print("   ğŸ”„ RÃ©vision complÃ¨te du systÃ¨me de rÃ¨gles nÃ©cessaire")
        
        # Recommandations spÃ©cifiques
        worst_col = min(sorted_cols, key=lambda x: x[1]['accuracy'])
        best_col = max(sorted_cols, key=lambda x: x[1]['accuracy'])
        
        print(f"\nğŸ¯ ACTIONS PRIORITAIRES:")
        print(f"   ğŸ“ˆ AmÃ©liorer les rÃ¨gles pour '{worst_col[0]}' ({worst_col[1]['accuracy']:.1f}%)")
        print(f"   âœ¨ Reproduire le succÃ¨s de '{best_col[0]}' ({best_col[1]['accuracy']:.1f}%)")
        
        if not self.other_columns_stable:
            print(f"   ğŸ”§ Corriger les modifications non-dÃ©sirÃ©es dans les autres colonnes")
        
        print("="*80)

def main():
    """Fonction principale"""
    
    comparator = TrainingVsOutputComparator()
    
    # SÃ©lection des fichiers
    training_file, output_file = comparator.select_files_gui()
    
    if training_file and output_file:
        # Analyser la performance du systÃ¨me
        comparator.compare_training_vs_output(training_file, output_file)
        
        print(f"\nğŸ‰ Analyse de performance terminÃ©e!")
        input("\nAppuyez sur EntrÃ©e pour fermer...")
    else:
        print("âŒ Analyse annulÃ©e - fichiers non sÃ©lectionnÃ©s")

if __name__ == "__main__":
    main()